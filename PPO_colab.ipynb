{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7JowRQEGGKQ"
   },
   "source": [
    "################################################################################\n",
    "> # **Clone GitHub repository**\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyGzuEMQF6sJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "################# Clone repository from github to colab session ################\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "run this section if you want to clone all the preTrained networks, logs, graph figures, gifs \n",
    "from the GitHub repository to this colab session\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "# !git clone https://github.com/nikhilbarhate99/PPO-PyTorch\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mrn6rpJpF8Sc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "run this section if you want to copy all files and folders from cloned folder (PPO-PyTorch)\n",
    "to current directory (/content/ or ./)\n",
    "\n",
    "So you can load preTrained networks and log files without changing any paths\n",
    "\n",
    "**  This will overwrite any saved networks, logs, graph figures, or gifs \n",
    "    that are created in this session before copying having the same name (or number)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "# !cp -rv ./PPO-PyTorch/* ./\n",
    "\n",
    "print(\"============================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-7AbGA2F8Ut",
    "outputId": "c6921fe3-fa71-42df-e3fa-c9af7eee6aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "run this section if you want to delete original cloned folder and the cloned ipynb file\n",
    "(after you have copied its contents to current directory)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "# delete original cloned folder\n",
    "# !rm -r ./PPO-PyTorch\n",
    "\n",
    "# delete cloned ipynb file\n",
    "# !rm ./PPO_colab.ipynb\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4VJcUT2GlJz"
   },
   "source": [
    "################################################################################\n",
    "> # **Install Dependencies**\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rbpSQTflGlAr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############ install compatible version of OpenAI roboschool and gym ###########\n",
    "\n",
    "# !pip install swig\n",
    "\n",
    "# !pip install gym==0.15.4\n",
    "\n",
    "# !pip install torch\n",
    "\n",
    "# !pip install cython\n",
    "\n",
    "# !pip install poliastro\n",
    "\n",
    "# !pip install roboschool==1.0.7\n",
    "\n",
    "# !pip install box2d-py\n",
    "\n",
    "# !pip install Box2D\n",
    "\n",
    "# !pip install pybullet\n",
    "\n",
    "# !pip install gym[box2d]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzZairIiGQ11"
   },
   "source": [
    "################################################################################\n",
    "> # **Introduction**\n",
    "> The notebook is divided into 5 major parts : \n",
    "\n",
    "*   **Part I** : define actor-critic network and PPO algorithm\n",
    "*   **Part II** : train PPO algorithm and save network weights and log files\n",
    "*   **Part III** : load (preTrained) network weights and test PPO algorithm\n",
    "*   **Part IV** : load log files and plot graphs\n",
    "*   **Part V** : install xvbf, load (preTrained) network weights and save images for gif and then generate gif\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s37cJXAYGrTY"
   },
   "source": [
    "################################################################################\n",
    "> # **Part - I**\n",
    "\n",
    "*   define actor critic networks\n",
    "*   define PPO algorithm\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UT6VUBg-F8Zm",
    "outputId": "2369a1ae-0ba8-41ab-aaa0-f216627b86f6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultivariateNormal\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "############################### Import libraries ###############################\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "# import roboschool\n",
    "# import pybullet_envs\n",
    "\n",
    "\n",
    "################################## set device ##################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    \n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## PPO Policy ##################################\n",
    "\n",
    "\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.state_values = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.state_values[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        state_val = self.critic(state)\n",
    "\n",
    "        return action.detach(), action_logprob.detach(), state_val.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            \n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        \n",
    "        return action_logprobs, state_values, dist_entropy\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "                    ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob, state_val = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "            self.buffer.state_values.append(state_val)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob, state_val = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "            self.buffer.state_values.append(state_val)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "            \n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "        old_state_values = torch.squeeze(torch.stack(self.buffer.state_values, dim=0)).detach().to(device)\n",
    "\n",
    "        # calculate advantages\n",
    "        advantages = rewards.detach() - old_state_values.detach()\n",
    "        \n",
    "\n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "            \n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "\n",
    "            # Finding Surrogate Loss   \n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            # final loss of clipped objective PPO\n",
    "            loss = -torch.min(surr1, surr2) + 0.5 * self.MseLoss(state_values, rewards) - 0.01 * dist_entropy\n",
    "            \n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        \n",
    "        \n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xCb_EyxF8cF"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "################################# End of Part I ################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr-ZjT_CGyEi"
   },
   "source": [
    "################################################################################\n",
    "> # **Part - II**\n",
    "\n",
    "*   train PPO algorithm on environments\n",
    "*   save preTrained networks weights and log files\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YY1-DzVCF8eh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "training environment name : CartPole-v1\n",
      "current logging run number for CartPole-v1 :  1\n",
      "logging at : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_1.csv\n",
      "save checkpoint path : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "max training timesteps :  100000\n",
      "max timesteps per episode :  400\n",
      "model saving frequency : 20000 timesteps\n",
      "log frequency : 800 timesteps\n",
      "printing average reward over episodes in last : 1600 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  4\n",
      "action space dimension :  2\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a discrete action space policy\n",
      "--------------------------------------------------------------------------------------------\n",
      "PPO update frequency : 1600 timesteps\n",
      "PPO K epochs :  40\n",
      "PPO epsilon clip :  0.2\n",
      "discount factor (gamma) :  0.99\n",
      "--------------------------------------------------------------------------------------------\n",
      "optimizer learning rate actor :  0.0003\n",
      "optimizer learning rate critic :  0.001\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2024-04-29 12:40:03\n",
      "============================================================================================\n",
      "Episode : 83 \t\t Timestep : 1600 \t\t Average Reward : 19.2\n",
      "Episode : 146 \t\t Timestep : 3200 \t\t Average Reward : 25.44\n",
      "Episode : 184 \t\t Timestep : 4800 \t\t Average Reward : 42.03\n",
      "Episode : 211 \t\t Timestep : 6400 \t\t Average Reward : 57.59\n",
      "Episode : 235 \t\t Timestep : 8000 \t\t Average Reward : 67.67\n",
      "Episode : 252 \t\t Timestep : 9600 \t\t Average Reward : 94.88\n",
      "Episode : 264 \t\t Timestep : 11200 \t\t Average Reward : 130.0\n",
      "Episode : 272 \t\t Timestep : 12800 \t\t Average Reward : 192.62\n",
      "Episode : 281 \t\t Timestep : 14400 \t\t Average Reward : 181.78\n",
      "Episode : 288 \t\t Timestep : 16000 \t\t Average Reward : 195.0\n",
      "Episode : 296 \t\t Timestep : 17600 \t\t Average Reward : 219.12\n",
      "Episode : 303 \t\t Timestep : 19200 \t\t Average Reward : 237.43\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:13\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 309 \t\t Timestep : 20800 \t\t Average Reward : 275.67\n",
      "Episode : 315 \t\t Timestep : 22400 \t\t Average Reward : 228.67\n",
      "Episode : 321 \t\t Timestep : 24000 \t\t Average Reward : 268.0\n",
      "Episode : 328 \t\t Timestep : 25600 \t\t Average Reward : 244.57\n",
      "Episode : 333 \t\t Timestep : 27200 \t\t Average Reward : 314.8\n",
      "Episode : 338 \t\t Timestep : 28800 \t\t Average Reward : 338.6\n",
      "Episode : 342 \t\t Timestep : 30400 \t\t Average Reward : 362.75\n",
      "Episode : 348 \t\t Timestep : 32000 \t\t Average Reward : 286.67\n",
      "Episode : 352 \t\t Timestep : 33600 \t\t Average Reward : 361.75\n",
      "Episode : 357 \t\t Timestep : 35200 \t\t Average Reward : 371.4\n",
      "Episode : 361 \t\t Timestep : 36800 \t\t Average Reward : 345.5\n",
      "Episode : 366 \t\t Timestep : 38400 \t\t Average Reward : 355.2\n",
      "Episode : 370 \t\t Timestep : 40000 \t\t Average Reward : 396.75\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:27\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 374 \t\t Timestep : 41600 \t\t Average Reward : 351.5\n",
      "Episode : 379 \t\t Timestep : 43200 \t\t Average Reward : 360.2\n",
      "Episode : 386 \t\t Timestep : 44800 \t\t Average Reward : 225.29\n",
      "Episode : 394 \t\t Timestep : 46400 \t\t Average Reward : 189.75\n",
      "Episode : 400 \t\t Timestep : 48000 \t\t Average Reward : 264.33\n",
      "Episode : 407 \t\t Timestep : 49600 \t\t Average Reward : 245.43\n",
      "Episode : 411 \t\t Timestep : 51200 \t\t Average Reward : 348.0\n",
      "Episode : 416 \t\t Timestep : 52800 \t\t Average Reward : 360.2\n",
      "Episode : 420 \t\t Timestep : 54400 \t\t Average Reward : 382.25\n",
      "Episode : 424 \t\t Timestep : 56000 \t\t Average Reward : 400.0\n",
      "Episode : 428 \t\t Timestep : 57600 \t\t Average Reward : 374.5\n",
      "Episode : 434 \t\t Timestep : 59200 \t\t Average Reward : 260.33\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:41\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 438 \t\t Timestep : 60800 \t\t Average Reward : 394.5\n",
      "Episode : 442 \t\t Timestep : 62400 \t\t Average Reward : 400.0\n",
      "Episode : 447 \t\t Timestep : 64000 \t\t Average Reward : 324.8\n",
      "Episode : 451 \t\t Timestep : 65600 \t\t Average Reward : 393.5\n",
      "Episode : 457 \t\t Timestep : 67200 \t\t Average Reward : 302.17\n",
      "Episode : 462 \t\t Timestep : 68800 \t\t Average Reward : 310.0\n",
      "Episode : 466 \t\t Timestep : 70400 \t\t Average Reward : 400.0\n",
      "Episode : 472 \t\t Timestep : 72000 \t\t Average Reward : 283.83\n",
      "Episode : 477 \t\t Timestep : 73600 \t\t Average Reward : 312.6\n",
      "Episode : 481 \t\t Timestep : 75200 \t\t Average Reward : 370.5\n",
      "Episode : 486 \t\t Timestep : 76800 \t\t Average Reward : 356.8\n",
      "Episode : 490 \t\t Timestep : 78400 \t\t Average Reward : 400.0\n",
      "Episode : 494 \t\t Timestep : 80000 \t\t Average Reward : 346.0\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:56\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 498 \t\t Timestep : 81600 \t\t Average Reward : 400.0\n",
      "Episode : 502 \t\t Timestep : 83200 \t\t Average Reward : 400.0\n",
      "Episode : 506 \t\t Timestep : 84800 \t\t Average Reward : 400.0\n",
      "Episode : 510 \t\t Timestep : 86400 \t\t Average Reward : 400.0\n",
      "Episode : 514 \t\t Timestep : 88000 \t\t Average Reward : 400.0\n",
      "Episode : 520 \t\t Timestep : 89600 \t\t Average Reward : 297.0\n",
      "Episode : 524 \t\t Timestep : 91200 \t\t Average Reward : 348.25\n",
      "Episode : 529 \t\t Timestep : 92800 \t\t Average Reward : 354.6\n",
      "Episode : 534 \t\t Timestep : 94400 \t\t Average Reward : 324.8\n",
      "Episode : 538 \t\t Timestep : 96000 \t\t Average Reward : 389.5\n",
      "Episode : 542 \t\t Timestep : 97600 \t\t Average Reward : 338.5\n",
      "Episode : 546 \t\t Timestep : 99200 \t\t Average Reward : 400.0\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:09\n",
      "--------------------------------------------------------------------------------------------\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2024-04-29 12:40:03\n",
      "Finished training at (GMT) :  2024-04-29 12:41:12\n",
      "Total training time  :  0:01:09\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "from gym.envs.registration import register\n",
    "\n",
    "################################### Training ###################################\n",
    "\n",
    "\n",
    "####### initialize environment hyperparameters ######\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "\n",
    "# env_name = \"SpacecraftEnv-v0\"\n",
    "# register(\n",
    "#     id=env_name,\n",
    "#     entry_point='two_body_gym:SpacecraftEnv',\n",
    "# )\n",
    "\n",
    "has_continuous_action_space = False\n",
    "\n",
    "max_ep_len = 400                    # max timesteps in one episode\n",
    "max_training_timesteps = int(1e5)   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
    "save_model_freq = int(2e4)      # save model frequency (in num timesteps)\n",
    "\n",
    "action_std = None\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "## Note : print/log frequencies should be > than max_ep_len\n",
    "\n",
    "\n",
    "################ PPO hyperparameters ################\n",
    "\n",
    "\n",
    "update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
    "K_epochs = 40               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"training environment name : \" + env_name)\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "###################### logging ######################\n",
    "\n",
    "#### log files for multiple runs are NOT overwritten\n",
    "\n",
    "log_dir = \"PPO_logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "log_dir = log_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "#### get number of log files in log directory\n",
    "run_num = 0\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "run_num = len(current_num_files)\n",
    "\n",
    "\n",
    "#### create new log file for each run \n",
    "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "\n",
    "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
    "print(\"logging at : \" + log_f_name)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "################### checkpointing ###################\n",
    "\n",
    "run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "\n",
    "directory = \"PPO_preTrained\"\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "directory = directory + '/' + env_name + '/'\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"save checkpoint path : \" + checkpoint_path)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "############# print all hyperparameters #############\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"max training timesteps : \", max_training_timesteps)\n",
    "print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
    "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
    "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"state space dimension : \", state_dim)\n",
    "print(\"action space dimension : \", action_dim)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    print(\"Initializing a continuous action space policy\")\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"starting std of action distribution : \", action_std)\n",
    "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
    "    print(\"minimum std of action distribution : \", min_action_std)\n",
    "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
    "\n",
    "else:\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\") \n",
    "print(\"PPO K epochs : \", K_epochs)\n",
    "print(\"PPO epsilon clip : \", eps_clip)\n",
    "print(\"discount factor (gamma) : \", gamma)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"optimizer learning rate actor : \", lr_actor)\n",
    "print(\"optimizer learning rate critic : \", lr_critic)\n",
    "\n",
    "if random_seed:\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"setting random seed to \", random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    env.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "################# training procedure ################\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# logging file\n",
    "log_f = open(log_f_name,\"w+\")\n",
    "log_f.write('episode,timestep,reward\\n')\n",
    "\n",
    "\n",
    "# printing and logging variables\n",
    "print_running_reward = 0\n",
    "print_running_episodes = 0\n",
    "\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "\n",
    "# training loop\n",
    "while time_step <= max_training_timesteps:\n",
    "    \n",
    "    state = env.reset()\n",
    "    current_ep_reward = 0\n",
    "\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        \n",
    "        # select action with policy\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "        \n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "\n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update()\n",
    "\n",
    "        # if continuous action space; then decay action std of ouput action distribution\n",
    "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
    "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "\n",
    "        # log in logging file\n",
    "        if time_step % log_freq == 0:\n",
    "\n",
    "            # log average reward till last episode\n",
    "            log_avg_reward = log_running_reward / log_running_episodes\n",
    "            log_avg_reward = round(log_avg_reward, 4)\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
    "            log_f.flush()\n",
    "\n",
    "            log_running_reward = 0\n",
    "            log_running_episodes = 0\n",
    "\n",
    "        # printing average reward\n",
    "        if time_step % print_freq == 0:\n",
    "\n",
    "            # print average reward till last episode\n",
    "            print_avg_reward = print_running_reward / print_running_episodes\n",
    "            print_avg_reward = round(print_avg_reward, 2)\n",
    "\n",
    "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
    "\n",
    "            print_running_reward = 0\n",
    "            print_running_episodes = 0\n",
    "            \n",
    "        # save model weights\n",
    "        if time_step % save_model_freq == 0:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"saving model at : \" + checkpoint_path)\n",
    "            ppo_agent.save(checkpoint_path)\n",
    "            print(\"model saved\")\n",
    "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            \n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print_running_reward += current_ep_reward\n",
    "    print_running_episodes += 1\n",
    "\n",
    "    log_running_reward += current_ep_reward\n",
    "    log_running_episodes += 1\n",
    "\n",
    "    i_episode += 1\n",
    "\n",
    "\n",
    "log_f.close()\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print total training time\n",
    "print(\"============================================================================================\")\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "print(\"Finished training at (GMT) : \", end_time)\n",
    "print(\"Total training time  : \", end_time - start_time)\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEy2qKdZF8ha"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "################################ End of Part II ################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHhK13_1G6zX"
   },
   "source": [
    "################################################################################\n",
    "> # **Part - III**\n",
    "\n",
    "*   load and test preTrained networks on environments\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZWyhkq9Gxm5",
    "outputId": "eb21c926-f866-4fb7-cbd0-4c14ba7b45b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "loading network from : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: 400.0\n",
      "Episode: 2 \t\t Reward: 400.0\n",
      "Episode: 3 \t\t Reward: 400.0\n",
      "Episode: 4 \t\t Reward: 180.0\n",
      "Episode: 5 \t\t Reward: 400.0\n",
      "Episode: 6 \t\t Reward: 400.0\n",
      "Episode: 7 \t\t Reward: 400.0\n",
      "Episode: 8 \t\t Reward: 400.0\n",
      "Episode: 9 \t\t Reward: 400.0\n",
      "Episode: 10 \t\t Reward: 400.0\n",
      "============================================================================================\n",
      "average test reward : 378.0\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "#################################### Testing ###################################\n",
    "\n",
    "\n",
    "################## hyperparameters ##################\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "has_continuous_action_space = False\n",
    "max_ep_len = 400\n",
    "action_std = None\n",
    "\n",
    "\n",
    "# env_name = \"LunarLander-v2\"\n",
    "# has_continuous_action_space = False\n",
    "# max_ep_len = 300\n",
    "# action_std = None\n",
    "\n",
    "\n",
    "# env_name = \"BipedalWalker-v2\"\n",
    "# has_continuous_action_space = True\n",
    "# max_ep_len = 1500           # max timesteps in one episode\n",
    "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
    "\n",
    "\n",
    "# env_name = \"RoboschoolWalker2d-v1\"\n",
    "# has_continuous_action_space = True\n",
    "# max_ep_len = 1000           # max timesteps in one episode\n",
    "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
    "\n",
    "\n",
    "total_test_episodes = 10    # total num of testing episodes\n",
    "\n",
    "K_epochs = 80               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003           # learning rate for actor\n",
    "lr_critic = 0.001           # learning rate for critic\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# preTrained weights directory\n",
    "\n",
    "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
    "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
    "\n",
    "\n",
    "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"loading network from : \" + checkpoint_path)\n",
    "\n",
    "ppo_agent.load(checkpoint_path)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "test_running_reward = 0\n",
    "\n",
    "for ep in range(1, total_test_episodes+1):\n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(1, max_ep_len+1):\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # clear buffer    \n",
    "    ppo_agent.buffer.clear()\n",
    "\n",
    "    test_running_reward +=  ep_reward\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
    "    ep_reward = 0\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "avg_test_reward = test_running_reward / total_test_episodes\n",
    "avg_test_reward = round(avg_test_reward, 2)\n",
    "print(\"average test reward : \" + str(avg_test_reward))\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6IYC_JCGxlB"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "################################ End of Part III ###############################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZewQELovHFt4"
   },
   "source": [
    "################################################################################\n",
    "> # **Part - IV**\n",
    "\n",
    "*   load log files using pandas\n",
    "*   plot graph using matplotlib\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "bY-E5HGcGxiu",
    "outputId": "2dd1e86f-e14a-440e-e61e-ab2ca8b0498c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "loading data from : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_0.csv\n",
      "data shape :  (125, 3)\n",
      "--------------------------------------------------------------------------------------------\n",
      "============================================================================================\n",
      "figure saved at :  PPO_figs/CartPole-v1//PPO_CartPole-v1_fig_0.png\n",
      "============================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAIlCAYAAAAwtKL0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACrtElEQVR4nOzdd3hUVfoH8O+0THonJBGkFxWwYAMLHUQFFX+ioi6suqICKwKioLigUlSa4i5rYQVFF12xFxRcQRELYFlARVS6hFBC6mTq/f1xvHPvTCbJ1Nw7k+/neebJtMycmZzMnPe+57zHIEmSBCIiIiIiIgqJUesGEBERERERxSMGU0RERERERGFgMEVERERERBQGBlNERERERERhYDBFREREREQUBgZTREREREREYWAwRUREREREFAYGU0RERERERGFgMEVERERERBQGBlNEREQhMhgM6Nu3r9bNICIijTGYIiKiiGzduhW33HILOnXqhLS0NKSkpKBDhw646aabsHbt2pg975gxY2AwGLBnz56At7dt2xYGg8F7MplMyM/Px+DBg/HWW2/FrF1NraamBgsWLMCoUaPQtWtXGI3GBt8XIiKKHrPWDSAiovjk8XgwZcoULFq0CGazGf3798fw4cNhsVjw22+/4b333sPKlSvx0EMPYcaMGZq00WQy4YEHHgAAOBwO/PTTT3j77bexdu1azJ8/H5MnT9akXdFUWlqKKVOmAADatGmDnJwcHD9+XONWERE1DwymiIgoLA888AAWLVqEM844A6+99ho6dOjgc7vNZsNTTz2FY8eOadRCwGw2Y+bMmT7XffTRR7jkkkvw4IMP4o477kBqaqo2jYuS/Px8fPTRR+jZsydyc3NxySWX4MMPP9S6WUREzQKn+RERUch++eUXPPbYY8jLy8OaNWvqBFIAkJKSgnvuuQezZs0CAPz888+YOnUqzjrrLOTl5SE5ORmdO3fGfffdh6qqqjq/37dvXxgMBtjtdjz44IPo2LEjLBYLZs6cibZt22LFihUAgHbt2nmn8gWzjmnw4MHo0qULampq8MMPP3ivf/fdd9GvXz9kZWUhJSUFZ5xxBhYvXgy32x30++JwOLBw4UKcddZZSEtLQ0ZGBi666CK8/fbbQf1+TU0NMjIy0LFjx3rv07lzZ2RkZKCmpgYAkJ6ejkGDBiE3NzfodhIRUXQwM0VERCFbvnw53G43xo4di5YtWzZ4X6vVCgB4/fXXsWzZMvTr1w99+/aFx+PBl19+iUcffRQbNmzAp59+CovFUuf3R4wYge+//x5DhgxBbm4u2rdvj4kTJ2L58uX4/vvvcddddyE7OxuAWCcVjieeeAITJ05Ebm4uRo0ahbS0NLzzzju4++678dlnn+G1116DwWBo8DHsdjsuueQSrF+/HmeeeSZuueUWOJ1OvPfee7jiiiuwZMkSjB8/vsHHSE1NxYgRI/DCCy/giy++QK9evXxu/+qrr7Br1y6MHj067jNqREQJQSIiIgpR3759JQDSunXrgv6dAwcOSHa7vc71s2bNkgBIK1eu9Lm+T58+EgDpjDPOkI4dO1bn90aPHi0BkHbv3h3w+dq0aSNZrdY613/44YeSwWCQUlNTperqaunXX3+VzGazVFBQIO3bt897P7vd7m3Diy++6PMYAKQ+ffr4XDd9+nQJgDRz5kzJ4/F4r6+oqJDOPvtsKSkpSTp48GDAtqqtXbtWAiDdeeeddW4bP358o+/7kCFDGnxfiIgoejjNj4iIQlZSUgIAaNWqVdC/c9JJJyEpKanO9XK2Zt26dQF/b9asWWFPYXO5XJg5cyZmzpyJ+++/HyNGjMCll14KSZLwyCOPIDU1FS+99BJcLhcmT56M1q1be383KSkJ8+bNAyAycQ3xeDxYunQpOnbsiAcffNAni5WRkYEHH3wQDocDr7/+eqNt7t+/P4qLi/Hqq6/C6XT6vJZXXnkFJ510Evr16xfiO0FERLHAaX5ERNQkJEnC888/j+XLl2P79u0oLy+Hx+Px3v77778H/L1zzz037Od0u93eNVtGoxE5OTkYMGAAxo0bh+HDhwMAvv32WwAIuN7q/PPPR0pKCr777rsGn2fnzp0oKytDcXGx9/nUjhw5AgD46aefAADfffcd3nzzTZ/7tG3bFmPGjIHRaMSoUaMwf/58rFmzBsOGDQMArFmzBkeOHME999wDo5HHQomI9IDBFBERhaywsBA//fQTDh48iC5dugT1O3/961/x1FNPoXXr1hg+fDiKioq866lmzZoFu90e8PcaW5PVEKvVitra2gbvU1FR0eDzFBQU4ODBgw0+hlyKfMeOHdixY0e996uurgYggin/oKtPnz4YM2YMAOCmm27C/Pnz8dJLL3mDqZUrV3pvIyIifWAwRUREIbvggguwfv16fPzxx+jfv3+j9y8tLcXf//539OjRA1988YVP8YSSkpKA2RxZY4UfIpWZmQkAOHz4MNq0aVPn9tLSUu99GnuMq6++Gq+99lqjzzlmzBhv4BRIjx490KNHD7z99tuorKwEALz99ts4/fTT0b1790Yfn4iImgbnCRARUcjGjBkDk8mEZ555xjuFrT52ux2//fYbJEnCwIED61Sh++yzz8Jqg8lkAoCQSpcHcuaZZwIA1q9fX+e2r7/+GjabDWeccUaDj3HKKacgMzMTW7Zs8VnnFIkbb7wRNpsNq1evxurVq2Gz2XDjjTdG5bGJiCg6GEwREVHIOnbsiKlTp+Lo0aMYOnQodu/eXec+tbW1WLhwIWbOnOnN+GzatMlnndSBAwdw3333hdUGuSjFgQMHwvp92ahRo2A2m7Fw4UKfdVtOp9PbtoaySIDYHPiOO+7A3r17MWXKlIAB1fbt21FaWhp0u2644QYYjUasXLkSL774onctFRER6Qen+RERUVgeeeQR1NbWYtGiRejSpQv69++Pbt26wWKxYPfu3Vi3bh2OHTuGRx55BEVFRbj66quxevVqnH322RgwYAAOHz6Md999F/3798dvv/0W8vP3798f8+fPx9ixY3HNNdcgLS0NJ598csgBR4cOHfDoo49i8uTJ6NGjB0aOHIm0tDS8++67+Omnn3DFFVcElRGaNWsWvvnmGzz55JN477330KdPH7Ro0QIHDx7Etm3b8P333+OLL75AQUFBUO0qLi5G//798d///hcAMGDAABQXFwe875QpU3D06FEAwLZt27zXpaenAwDuu+8+dO3aNajnJSKiEGhcmp2IiOLc5s2bpZtvvlnq2LGjlJKSIlmtVqlt27bS9ddfL3300Ufe+1VWVkqTJ0+W2rZtK1mtVqlTp07Sww8/LDkcjoD7Nsl7PDXksccekzp16iRZLJY6j1HfPlP1eeutt6Q+ffpIGRkZktVqlbp37y4tWLBAcjqdde4bqL2SJEkul0t6+umnpQsuuEDKzMyUrFardPLJJ0uXXHKJtHTpUqmqqiro9kiSJK1YsUICIAGQVqxYUe/92rRp471foNMnn3wS0vMSEVFwDJIkSZpEcURERERERHGMa6aIiIiIiIjCwGCKiIiIiIgoDAymiIiIiIiIwsBgioiIiIiIKAwMpoiIiIiIiMLAYIqIiIiIiCgM3LT3Dx6PB7///jsyMjJgMBi0bg4REREREWlEkiRUVlaiuLgYRmP9+ScGU3/4/fff0bp1a62bQUREREREOrF//360atWq3tsZTP0hIyMDgHjDMjMzm+Q5nU4njh49ivz8fFgsliZ5Top/7DcULvYdCgf7DYWD/YbCoad+U1FRgdatW3tjhPowmPqDPLUvMzOzSYMpu92OzMxMzTsMxQ/2GwoX+w6Fg/2GwsF+Q+HQY79pbPkPC1AQERERERGFgcEUERERERFRGBhMERERERERhYFrpkIgSRJcLhfcbndUHs/pdMLlcqG2tjZqj0mJL5r9xmQywWw2czsAIiIiojAwmAqSw+HAoUOHUFNTE7XHlCQJHo8HVVVVHMxS0KLdb1JTU1FUVISkpKQotI6IiIio+WAwFQSPx4Pdu3fDZDKhuLgYSUlJURnEejweuFwumM3mBjcDI1KLVr+RJAkOhwNHjhzB7t270alTJ/ZDIiIiohAwmAqCw+GAx+NB69atkZqaGrXHZTBF4Yhmv0lJSYHFYsHevXvhcDiQnJwcpVYSERERJT6O4EPAgIcSEfs1ERERUXg4iiIiIiIiIgoDgykiIiIiIqIwMJgi3Vi/fj0MBgNOnDihdVOIiIiIiBrFYIooTDt27MDVV1+Ntm3bwmAwYPHixVo3iYiIiIiaEIOpZsbhcGjdBF20IRpqamrQvn17zJs3D4WFhRE/XqK8L0RERETNBYOpcEgSUF2tzUmSQmpq3759MX78eEyaNAn5+fkYNGgQfvjhB1x66aVIT09Hy5YtcdNNN+Ho0aMAgHfeeQfZ2dnweDwAgO+++w4GgwH33HOP9zHHjh2L66+/HgBw7NgxXH/99WjVqhVSU1PRvXt3/Pvf/260DQDw/vvvo3PnzkhJSUG/fv2wZ8+eoF9XY8/79NNP46STTvK+Dtnw4cMxevRo7+VHHnkEBQUFyMjIwK233or77rsPZ5xxRlBtOOecc/D444/juuuug9VqDbrtskDvy549e2AwGPDdd99573fixAkYDAasX78egJgOabVa8fHHH+Pss89GamoqevfujZ07d3p/5/vvv0e/fv2QkZGBzMxM9OzZE1u2bAm5jURERERUP10FU3PnzoXBYMDEiRO910mShJkzZ6K4uBgpKSno27cvduzY4fN7drsdEyZMQH5+PtLS0jB8+HAcOHAgdg2tqQHS0yM+GTMzkZSbC2NmZvC/V1MTcnNXrFgBs9mMzz//HPPmzUOfPn1wxhlnYMuWLVizZg0OHz6MkSNHAgAuvvhiVFZW4ttvvwUAbNiwAfn5+diwYYP38davX48+ffoAAGpra9GzZ0+8++672L59O2677TbcdNNN+Oqrr+ptw9NPP439+/djxIgRuPTSS/Hdd995A5lgNfa811xzDY4ePYpPPvnE+ztlZWX48MMPccMNNwAAXnrpJcyePRuPPvootm7dipNPPhlLly4N+f2NhP/7EooZM2ZgwYIF2LJlC8xmM26++WbvbTfccANatWqFzZs3Y+vWrbjvvvtgsVii3XwiIiKi5k3Sia+//lpq27at1KNHD+muu+7yXj9v3jwpIyNDWr16tbRt2zbp2muvlYqKiqSKigrvfW6//XbppJNOktauXSt98803Ur9+/aTTTz9dcrlcQT9/eXm5BEAqLy+vc5vNZpN++OEHyWaziSuqqiRJ5Iia/lRVFdL72qdPH+mMM87wXp4xY4Y0ePBgn/vs379fAiDt3LlTkiRJOuuss6T58+dLkiRJV155pTR79mwpKSlJqqiokA4dOiQBkH788cd6n/PSSy+VJk+eXG8bJEmSpk2bJp1yyimSx+PxXnfvvfdKAKSysrKQXmN9zzt8+HDp5ptv9l5++umnpcLCQm+/OO+886Rx48b5PMYFF1wgnX766SE/d5s2baRFixaF9DuB3pfdu3dLAKRvv/3We11ZWZkEQPrkk08kSZKkjz/+WAIgffTRR977vPfeexIAbx/NyMiQli9fHlQ76vRvSlgOh0M6ePCg5HA4tG4KxRH2GwoH+w2FQ0/9pqHYQE0XmamqqirccMMNePbZZ5GTk+O9XpIkLF68GPfffz9GjBiBbt26YcWKFaipqcHLL78MACgvL8eyZcuwYMECDBw4EGeeeSZWrlyJbdu2Yd26dbFpcGoqUFUV8clTUQHH8ePwVFQE/3upqSE39+yzz/ae37p1Kz755BOkp6d7T127dgUA/PrrrwDE9LP169dDkiR89tlnuOKKK9CtWzds3LgRn3zyCVq2bOn9HbfbjdmzZ6NHjx7Iy8tDeno6PvroI+zbt6/eNgDAjz/+iPPPPx8Gg8F7Xa9evYJ+TcE87w033IDVq1fDbrcDEJmo6667DiaTCQCwc+dOnHvuuT6P63851vzfl1D06NHDe76oqAgAUFpaCgCYNGkSbr31VgwcOBDz5s3z/m2JiIiaDbcbKC8Hamu1bgklMLPWDQCAcePG4bLLLsPAgQPxyCOPeK/fvXs3SkpKMHjwYO91VqsVffr0waZNmzB27Fhs3boVTqfT5z7FxcXo1q0bNm3ahCFDhgR8Trvd7h1kA0BFRQUAwOl0wul0+tzX6XRCkiR4PB5lDU5KSsSvW5IkSC4XJLMZHlVQ0cgvhbxuKjU11dtut9uNyy+/HPPmzatzv6KiIng8Hlx88cVYtmwZvv32WxiNRnTt2hUXX3wx1q9fj7KyMlx88cXex5s/fz4WLVqEhQsXonv37khLS8Pdd98Nu93us15J3QYA8Hg83vdUfZ3803+tk79gnveyyy6Dx+PBO++8g3POOQefffYZ5s+f7/PYDbUhVP6PFQz/90Xmdru918v9VH5fpD/+/maz2Xsf+TqXywWPx4MHH3wQ1113Hd5//3188MEH+Nvf/oaXX34ZV111VZ3nkh/T6XR6A01KTE6nEy6Xq85nHFFD2G8oHJr3G0kCjh4F5OcvKADMuhj2UgM07zd+bQmG5r1q1apV+Oabb7B58+Y6t5WUlAAAWrZs6XN9y5YtsXfvXu99kpKSfDJa8n3k3w9k7ty5mDVrVp3rjx496hNkAcoA1eVyweVyBffCgiBJEtxuNwD4ZGiiSR7gy+0+44wz8MYbb6BVq1YwB/hQcblc6N27NyorK7F48WJcdNFFcLvduOCCC/D444+jrKwM48eP9z7ep59+imHDhuG6664DIAbmu3btQteuXb338W8DAHTt2hVvv/22z3VffPGFtw2Nvc/BPK/FYsGVV16Jl156CT///DM6deqE008/3Xt7586d8dVXX3mLaQDAli1bIElSWH9nt9sd0u8Fel/kfnzgwAF0794dgMgmqh9f7jPq9ynQde3bt8f48eMxfvx43HTTTXj++ecxbNiwOu2Q+3dZWVnAPkGJw+VyoaysDAD4t6agJUy/sdlgqK0FkpIgpaVp3ZqEp3W/MVRWwlBd7b0sVVdDys5u8nZQaLTuN2qVlZVB3U/TVu7fvx933XUXPvroIyQnJ9d7P/9AQ5KkRoOPxu4zbdo0TJo0yXu5oqICrVu3Rn5+PjIzM33uW1tbi6qqKpjN5qj+YdUZhlgFUwaDAUaj0dvu8ePH41//+hf+9Kc/YcqUKcjPz8cvv/yCV155Bc888wxMJhPy8vJwxhln4OWXX8bixYthNpvRr18/jBo1Ck6nE/379/c+XqdOnfD666/j66+/Rk5ODhYtWoTDhw/jlFNO8d7Hvw0AcMcdd2Dx4sW49957cdttt2Hr1q148cUXve9HY+9zMM8LiKl+V1xxBX788UfceOONPreNHz8eY8eOxTnnnIPevXvj1VdfxbZt29C+ffug/s4OhwM//PCD93xJSQm2b9+O9PR0dOzYMeS/DQBkZGTg/PPPx4IFC9ChQwccPXrUG/SbTCaYzWZv9kj9PqmvczqdmDp1Kq6++mq0a9cOBw4cwNatWzFixIiAr8tsNsNoNCInJ6fB/0OKf/JRtvz8fBYkoaDFfb+prQUqKkRWIj1dXJeZCYRRhZWCp2m/sdtFRsr/Oy0nh9kpndPT502wlZo17VFbt25FaWkpevbs6b3O7Xbj008/xVNPPeUt9VxSUuJdEwKIdSFytqqwsBAOhwNlZWU+2anS0lL07t273ue2Wq0B3ySLxVLnj+d2u70DX6MxesvMPB4PDAaD97FjRf34rVq1wueff457770XQ4cOhd1uR5s2bXDJJZf4BHX9+vXDN998g379+sFoNCIvLw+nnnoqfv/9d5x22mne+z344IPYs2cPhg4ditTUVNx222248sorUV5e7vOa/F9j27ZtsXr1atx9991YunQpzj33XMyZMwc333xzUO9zsM87cOBA5ObmYufOnbjhhht8brvpppuwZ88eTJ06FbW1tRg5ciTGjBmDr7/+Oqi/R0lJiU/fXbBgARYsWIA+ffp4y5g3JtDf/l//+hduvvlmnHvuuejSpQsee+wxDB482Pu+yO+9+nfVPy0WC44fP44xY8bg8OHDyM/Px4gRI/DQQw8FfF3yYwbq+5R4zGYz/9YUsrjsNw6HCKIcDsBgANRtt9mUwIpiRpN+4/GIrWTk57RYlKl+dntUlmlQbOnl8ybY5zdIUogLcKKosrLSO11P9uc//xldu3bFvffei9NOOw3FxcW4++67MXXqVAAiA1BQUIBHH30UY8eORXl5OVq0aIGVK1d6y3sfOnQIrVq1wvvvv1/vmil/FRUVyMrKQnl5ecDM1O7du9GuXbuoHrmXp3jJmQHS3qBBg1BYWOjNkulRtPtNrPo36Y/T6cSRI0fQokULzb+kKH7EXb9xOkUQ5TdlH0lJYqAtT63OyeHAOoY06zdlZSJYBsTfPDcXKC0Vf3sAaNkS4Ppg3dLT501DsYGappmpjIwMdOvWzee6tLQ05OXlea+fOHEi5syZg06dOqFTp06YM2cOUlNTMWrUKABAVlYWbrnlFkyePBl5eXnIzc3FlClT0L17dwwcOLDJXxPFj5qaGvzzn//EkCFDYDKZ8O9//xvr1q3D2rVrtW4aEVHsuFyiylmiTXNzuYDKSmUgLTObxbS+5GQRYB07Jq6vqBDXxWiafYPcbvG8kRwQk4+Fa9F+vbLZlL+/0SgCZqMRSEsTfQMQP7l2iqJI9xNHp06dCpvNhjvvvBNlZWU477zz8NFHHyEjI8N7n0WLFsFsNmPkyJGw2WwYMGAAli9fzspkcWzo0KH47LPPAt42ffp0TJ8+PeLnMBgMeP/99/HII4/AbrejS5cuWL16tTcIT29gCsgHH3yAiy66qN7b9+3bh1NPPbXe23/44QecfPLJ4TeeiCgcHo+ocObxiKyMX/GmuOR2i61DVMUGAIjsQ0aG75YiVqs42e3i96qrm366n80msieAyJxYrSKoC/YovMcjAoLqavEa8/K4DggQf88TJ5TLWVlKBiotTfQRSRLvf0YGs1MUNZpO89MTTvPTl4MHD8Lmf3TxD7m5ucjNzY15G3755Zd6bzvppJOQ0sD0EJfLhT179tR7e9u2bcMuZsJpfgRADKhOnBBH43NzgxpM6Wn6BGmkpsZ3wJmWJgadDdBtv/F4lCBKPZQxGpUgKlDWxukEjhxR7ltQEFmGKBSSJKac/VGB1YfJpARWVmvdtkuSeK1VVcqUNUD87+fnN91rCFKT95ujR8X6OCDwgQJ5T08gqH5P2tDT501cTPMjqs9JJ52kdROCqshXH7PZHNHvEzVIkoDjx5WBQ2VlYmQYKPb81xHJ2Y14KsYgFxiQMw0yg0G8jvT0hqe+WSwi0KqpUQKyBgZKUVVdrQRSBoNv+91u0aaaGnGbOmvlcolgIND2Gy6X+DzIy2u+U/5sNuXz0GQKHCilpyuBd02NuJwo2SmPR5zcbuW8xyP6Q1pa8+0XTYTBVAiYxKNExH4dh8rKlIEDUHeATFQfua+oB/IVFSKroZ4Op0cNBVFpaWJwHGx2JiNDDMDlbE9aWuwH1vL0PFmLFqLttbXi72K3K69LkpTrKirqPlZqqjgdPy4e1+EQGcfmelBFPZMlKytwP5DXTsn9p7q66YLoWKqs9O1X/jyexHidOsZgKghymrGmpqbBqV1E8aimpgZA8CVASWMnTojBl5o8mEpK0qRJFCccDmV6mLxGRx6onzghBpt6mOprt4tsi/pIu9strvMPolJTw8swmEy+A+uKitgHIuogMDVVmZqbliZOkiT+RrW14hRoKmBSkggW5M/rvDwxvU1eC2QyNb+Bs8ejHCQwmRruw+rslLxeTmfTI0MiScrUxfrYbM2vTzQxBlNBMJlMyM7ORmlpKQAgNTU1Kpvscs0UhSNa/UaSJNTU1KC0tBTZ2dks2BIPKivF9BRADCSTk5UjsnY7gylqmDqDabWKAb1chAEQGc+8PG36kd0u+nJtre96oPqkpkZeRCA9XZnqJ+87FauDSur32WAQbfdnMCgFMrKyRPAoZ60A8Zr9D+haLCIIPH5cXK6qUgLF5qK2VglSGzvgLWdg5YCqKad4xoI6m2mxiL5jNIo+UF0tgnO3W6wT5AHTmGEwFaTCwkIA8AZU0SBJEjwej89GrESNiXa/yc7O9vZv0rHqat+pHNnZYtCrDqYCDdCIZOqMplwWPStLCSbktXj5+U1THc7lEv3aZgsugJILNESrEpvRKAIoOTtXUSGCyViorFQGvcFOKTSblTVgDUlOFn/H8nJxuby88QxNIpEPMAHB7RsmB9GSJP4n4jmYUk9vzMz03e5AnrEAiNfJYCpmGEwFyWAwoKioCAUFBXDKO2lHyOl0oqysDDk5OZxiRUGLZr+xWCzMSMWD2lploASIgZM8aDCbxaBUnsLFLLcvj0fsKyRJYqDcXPu7xyOOTgNiUKV+H7KzlalSHo/IUOXnx3bRusOh/F3U5Iyr1SraKB9lj1W/TktTikLY7bE5gu9yKQN+OYCLtrQ0pUQ8IKZttmyZ+IUH3G4lYDCbg/vbmUzifg6HMp00Hj835XV1gGi/f0Y5OVn53qit5cG2GGIwFSKTyRS1wafJZILZbEZycjKDKQoa+00z43Yre9IAYiCmnsKTnKwMoOz24I7MNic1NUoQUVPTfAcUgbJSMoNBlNc/ckQMLp1OkaWJVelop9M3kJIDKPnUlAGAXAFQHnRWVUV/7ZS6gEQs1+hkZipTA+Vso96LikRKnZkJ5bNPDqYA0R/jcQNr+eAHELiUvskkAiyHQ7xGt7v5HkyKsTgMxYmImpGKCt/1AP5TUtSDAFb1q0sdRERpVkFcUveNQNO/DAYRRMgDMnn6XbS5XL6BlNUKFBaK505J0SaTkpqqBDg2W+DCD+GSC0oATbOWSZ31aqwwQSIIN5hSZ3HUlVHjifqzrb7Xrv5f9y9cRFHDYIqISK/kRfmAGOwFyhQkJSkDUH5Z+lJPAQIYTAGBpwPJLBbfPnbiRHQDC7dbBFLy0fSkJJER03oqmlxaXRbNIESdlcrIiP1rTUpS/r4uV2IfYJGzqIB4zaGs81PP6ojHzwV5vRegFC4JhMFUk2AwRUSkR5Lku04qMzPw9CD1F6l6XQzVHTy43dENDuKFuiR6Y5X61BXj5IIU0diLzu0WJbzl999i0UcgJVNvbCpX+ItUba3vep6mmnLXXLJToRaeUDOblc/TeMxM+W9zUN//kdmsBJnqaYEUVQymiIj0qKpKHHkFxAC4oYGY+qgkjz4qAr0XzTHYbGyKn7/sbGUAJq+fioRcBEQOpMxmUQxET4v+1ZsWy3sQRUr9vjVlxbjkZN8BtFZ9PtYD93Cn+Mnk7JS8j1k8UX+2NfY/zexUzOnok4yIiACIIEp9RDk7u+H7q78sE3laTyjUG3mqNcdgqqHiE4EEWj8V7iBMzm7JBwb0GEjJ1BkdeR+icNXU+B4Maeoy5eppi9EIDENVUQGUlMAYrcymP3n/JEDZWylU8bxuSg4k5eItDWEwFXM6/DQjImrmysuVAUh6euNrAUwm5T7q6R/NWX2Ls+Nt0BSphkqiN8Ri8cmmGNWFUEJRUaG85yaTvsvTm0xKX/F4fKeRhUKSfPeE02Ifo1gW1WhMdbVyMMjhiN5UUbVIs1JA/AZT6s/4QFX8/CUlKX1BvckvRQ2DKSIiPampUTIqJlPwpbxZ1c+XOphKS1MGE80tM6XuC6GWf05LU45qezyhr7+pqVGyInL5db0GUrJorDeqqfHNmjS2Ti0WDAbfaYvhBoahstt913rK16m3d4iUJPlmZsINpuK1CEU4gaT8f6zem4qihsEUEZFeeDy+6yyys4NfoM+pfgr1FD95r5V4Xh8RiVDWVgSizqpUVQWf9XQ66240HQ/74lksStDpdodeHl4PWSmZ/1S/WGckXC6RhZKpS93X1orqkNEQbPGFxhiNvmsD4yVjE0wVP3+c6hdT3LSXiEgP3G4xEJEHCSkpoWUS5BLpPPLoO5VFHkQkJSnvi9Op/wxJtMiv2WAIL5gxm8WgXN4bqrKy8c18PR7fqV1pafG1eWx6uvK+VVWFlvlQB5wpKdoGkPK0RZtNmbYYq32u5CIj6v+7jAx4qqt9qyQajZEHmJFU8fNnsYggUJLEz2j+vRwO8Z4cOyb+H44fF4GMy6VUFnW5xHtnNConk0n5aTaLNsk/5aycxSJmLRw/Lj7brFbxvtZX9VWeDqguqU5Rw2CKiEhr8kamcsYknAGHfJSytlY8jtMZH5mAWAiUjVG/Fw5H0xcE0EKoayvqk57uOyBOT284GC0rU/pyUpK22ZlwWK2ivzid4mS3B3dgw38qZLBTdGMpPV3JrlVXxyaYkouMqMve5+SIzzWrVbRBfl+qqsTnm3o6ZajPJf9/G42hT131l5SkvD8OR/CfmZIk+vnevcDu3cBvv4mTfP7gQW0KfxgM4mBHdrY45ecD7dsDHToABQVAcTHQtq2YcqvF9NMExWCKiEhLdrvvUfxIFunLwZT8uM0xmKpvsBWv6yMiEWpJ9PqYTJDU628qK+uvMFlR4TvFUl0VMJ7IR/0BMSgOZtBeWembjQtlE9lYsVjEoNnhEMFNbW30DyScOOFbZMR//7CUFPFeyNP8Kip8i32EorbWN/sVad/y/1yQ+3dpqTgdPqz8PHAA2LdPOQUTLBmN4n8gL0+8L/J7YTIpmSejUTyvPAXZ4xEnl0vZmFg+2WzKZszyQTOHQ9nTTJLE+9zYlMr8fKBLF6BTJ9/TySfH7/+shnTwn05E1EzV1Ph+6VkskZWN9t9vKtyjv/Es0BQ/QBm8yAOQ5iCS4hN+pLQ05X2Vs1P+wUJFhZKBkMurx+t0yuRkpb/I2d6GXovbrUw/Mxj0kZWSpacrgaHNFt1gymbzLQZRX5GR1FTfNaGVleEFU5FW8fN4RFD088/AL78A+/cDu3YBv/8OHDoElJSEVqyjoABo105kf+Sf7dsDrVqJgCUrK3rbADidwJEj4rzVKr4r1GprxTpFOZgqKxOv57ffgF9/Fa931y5x/dGj4vT553WfJyVFtP+kk5SfxcXKqahInJpDdj9IDKaIiLRQWem7UD05OfIjgvJu9y6XcpSyuR1hbKjggsWiHPl1ufSROYglOWiUj4RHwmhU1t8AYlCcmyvOezxigKYO3jIz438aUWqq8j9aXd3wdEV16fj0dH3to6VeLxPtEuDqv3l2dsPZ8PR0JYMif0aF0kc8HuX/22Rq+ACBxyOm3H37LfD998BPP4kAateu4IqKpKeLQEk+tWghAos2bUT25uSTxeVI12yFQt3uQIFMcrI4tWxZ/2PIQdTeveLnb7+J92TXLhFsHT0qnke+riF5eeI9aNUKaN3a97x8aiYBV4J/kxAR6ZDD4RtIpaU1vqg/WFarslmowxH5moJ4op7iF6jSlcWi3O50JnYw5XYrg/tovc60NGWzVHlQbDD4rpcBRNARq0IHTUkdTNXUiGxToIMT8vQrQARRenvtcvER+W/XWJYtFHJwFszmsYB4T+XfsdlCC6bqy0p5PGLg/9VXwNatIoD67jvfz1g1i0WsIerYUQRH+fkiMCgqAk45Rawp0tvfEKh/77xQJCeL/8/u3cVP/9kLtbUiS3fggDgdPCh+HjokrpdPdrtSXOP77+t/vhYtRFB18snivW7b1vfU2Ib0cSKBv0mIiHRKPdc+IyO6U4LUA+fmtnlvYyWT1QM3p7Npjyo3NTmgBqIXTBkMYvAllzw/ccI3aJPXhyRKAO9fDa+2NnCfUQ/a9ZaVksnrpoDoVbOUM7yACFCCyYKnpCibkttsYkAfbPZcDqbKyoBvvgG2bBEB1FdfBd7HymoVQcMZZwCnnQZ07ixObdv6/k+op1tnZOgzkJLXTwG+m/CGKiVFmWoZaCp4crIyVbE+csEROejav18JvvbvV041NWJa4pEj4u8VSGamkun7I9tnKC6GpWVLYNCg8F6jBhhMERE1JfVUlUiqWtVH/SXbnPZTAhrfU8m/ol8ii0UwBYjMQnW17+AOEAO8eF4jVZ/UVN9qeP7BlLz4HxCvXY8DccD3QEK0qlmq/4eCzTDJGSw5QLXbG26LywVs2wZs2gSsXy+yTr/+Wvd+ycnA2WcD55wDnHmmOHXpElwRHv+DLHoU6VoxmcmkVKqUM5Wh/s8aDCKTl5cngtVA5GqH+/aJwGrfPjG1cM8ecdq7VxT2qKgAtm8Xpz+YAWT27An07Rs3RZQYTBERNSWbTTmSr97UMlrUX4zNLZhSL4QPNECT925pDkUoYhVMycUV1JmAtLTQMgzxxGr1XYfov9ZOvcl2fdMA9cA/mIqGcIIpwDdAralR/lclSQy85WzT11+LaXuBCkJ07Aj06gWcfz5w3nlAjx7hD7zlinoej34PskS6+bZacrLy+We3x2YPOLkYSW6uyAwGUlPjWx1x3z7g55/h2bcPrk6dkBRHB2YYTBERNSX1wCAWX2LNNZiSN78EGt5TSd5XRt6kM1HXTcUqmALEQQB5zVRGRnxtyBuOtDRlamN1tbK+UX4PAPEe6/l9MBqVoFAuAR5p4BduMGW1is+p8nJg40ax3mnzZhFAlZTUvX9WlpJtOussMf2roSIL4bBYRGAhlyfX00Be/psB4n2OtG3JycrUVJtNu36bmgp07SpOgOiTJSVwOxyoLC9Hnh6ny9YjQb9FiIh0SN4rBBBf3rGYwqD+AmpOa6bUVcUaGthZLL6bdCZ6MGU0xmYNT05O9B9Tr+R1Jv7rfNRZqXjYmDgpSfQLSRKfQ5FUW1RXBpQzO43Zuxf45BMRQH3+uaiw589kElmm885TTh06iCpz8mvIzw+/3fVJSlI+QxwOfa2njGZWChCfgXKGXk9VX+UgH4AUZ5/L8dVaIqJ4FuusFCC+FOUpK80pM6U+St5QAYTmsHmv+m8fZ4MSXZLLwtfUiPdWDsbVBQHioQR0UpLyGRRqWXJ/6v+d+h5n/36kvPMOTN9+C2zYINbK+CsuFmudLr5YBE5nnVX3s1EdtMYqyPH/XNBTMBWt9VJqyckiyypXQNXD6w2mT+kUP2WJiJqCfFQbEAFPLL+8TKbmF0zJR5XlMtD1aQ7BVCyn+DVXaWlKIFJd7Zv1jYesFBDdAiz1ZYJ37wb+8x/g1Vdh2boVPvlLs1kUiOjTR6x16thRyXC2aFH//20sggl/sVhTFg3q9Z1yRika5GAK0E8wpXrfpTgpPCHjpywRUVOorfUt2x3L+eAmk/IF7PHos1RzNKnXSzV2RDMWa0f0hsFU9MnTctVTdQGRBY2Xo+hy+fJobN6r/v2DB4HXXxdB1Nat3qsloxHO00+HacAAmAYOBC64wLd6aXW1shbNZgscTMkV5wDxXsfqs0yvxWliFUgmJSl9wW7Xx+eges8yPa1ZCwI/ZYmImkJTTPGT+ZdHT/RgKtgpfjKLRVk74nLFTfndoKmDqUR7bVpKS1P2I5LFS1ZKJq8NirTQQkUF8N57wL//LcqWy4xGoF8/4Jpr4Lr8chw1GNCiRQuYAvVD9Vq0+jZFVgcTsf7cVBencTr18b8T7fVSMv8S9Vpv8K6eSWGxKBVv4wSDKSKiWHO7lWkxJlPsv7T8K/rpYVAgk/flSU6O3hH9YItPqO8jD9L0MmiKJmamYkMe/MtZ0JSU+Os7kRZa+OYb4JlnRBAlr2UyGEQANXIkcNVVQEGBuN7pFBu21sdobHjPKf+p0bFel+ZfnEbrv61cIAIQ/8fR/l+W33tAfCZrGUz5V4ZUf6bHAX7KEhHFWlNmpQB9lkevrQWqqpQvzepqoLAwOlNL1NNDghkA+a8d0XNJ63DIwVQcTpfRNYNB9JWqKmW/rXjjvzYomGCqogJ4+WXg2WdFMCU76STgT38Cxo4F2rQJrz0pKcqA3mYTA3w5Yyxn0ABxfaynocV6816HQ5lmHAx1VioWa5rk91QuQiGX/NeC+v2Wy9THEQZTRESx1tTBlJ7Ko9tsYvDpPziR5+pHerTZ7VYCRnkdQGMSuQiFPBAFmJWKhcxM0X9ikSloCsEWWpAksfeTnIWSP8OSkoDLLhNZqAsvFPs9RZLBkddByVUS1QGUWlMUSIhmgQ5/VVVKJs9qFVNGG/vsi3XhDYNByQLJa8W0ysaFu2eZTsThJwERURyRv6gAZbPKWNNDZsrtBo4d851yBigDJyA6wVQ4X8JyBksuJqCHxdfRov57x+NgPx7oofJZuBrr+ydOAC+9JLJQ33+vXN+1K3DbbcBNNykHMAyGyPuYOtsHBA6kmmJqtNwW+b2R11RG43PB5VI2yQXE557dLl5XWpp4/f7rWuV1TEBsA/fkZCULVFurfTBlMsVlNp2ftEREsdTUWSlAH8GUzeYbSCUliUpeVitQUhK9qSWhrpeSmc1KVsrtTpzAg+ulqDFJSUrfl/eb+vJLkYV65RUlI5KcDFxzjQiiLrhABBZuN3D4sPI40Qg20tLEc8oFMcxmZVBtMjXNFD+Z/3sTjSCuvFwpqCBPqwPE662oEIFWcrI4yZm6WBWe8JecrFRUrK3VZuqqHLgC2q9TCxM/aYmIYkUOGABlsXVTMBqVL22tpvmpg7jsbN9AUj21xOWKbNCvXi8VajAli7QNesJgihojD1jLy0UW6oUXgO3bldtPO03JQsn7QMliMR3LZBLTBfXAfwpwpMGUPHUREK+zoEBcrq5WrpcLbchBrNXq+/kZ6z0J1ZnKSCo8hivOp/gBDKaIiGLH4VCOuDXl0VVABFTq9URNTf28/gMS/6kl6r1nQn0OOXiQ99AJljrQ0EuRjmhgMEWN2bYNWLwYePNN5WBPSgpw7bUiiDr//Pr/lxJg4NugaG7e6/EoWR9AZOHlqoTJyeJ/tbpazF5QlwJXZ9vlYCeWkpOVbFxtrcgUNqUE6FP8pCUiipVQ9z+KJnkDSo9HmzVB6gDFfz2A+r2IJJiK5EtYffTVf11XPGMwRYHYbGIK3z/+IQpLyDp3BiZMAG68UWSQG5MAA98Gmc1KVj/S4jSVlb7VCP1nJpjNIsDKzFS2jKit9f3sbIqp4Skpypquigpl/Zr8nSGv7YrVzAr/Sn5x+HnMT1oiolgJdz1PNKiDBY+n6aduyIMIk6luICcvqHa5xCDC4wlvY+FIglU9rCuLBXlgEuh9p+Znzx4RQC1bBhw/Lq6zWIBhw0QAde65YopdMIG3x6P0r1AzwfFEPQ053GlvDofIOgHifWpobajBID6/rFZxP5dLyRg2RZZI/XksSXU/D+Uy9XL7onmQRh20xnGfYjBFRBQL/tWYmjqYUQcnTT0PXv2FXN/zWq3KEUi7Pbx1AZEEq3KwoS4lHu/cbmW6ELNSzZckAevWAU89BbzzjtIn2rYVe0LdfLPIeMiluh2O4PqLOoOQiFkpmXqfI6czvM9O9fS+jIzQHsNsDj9bH66sLN8NqeU+I0nKebsdKC0VAV5GRngHwPwlSKaTn7ZERLGg5RQ/QNvMi7roRX1fuMnJypHbcIIpjyf89VIyk0k8RqJkpjjFr3mrrhbFJJ58EvjpJ+X6wYOB8eOBSy9VPhfUn0/BblydIAPfRvmvmwp1elt1tW+2panXIIXDagVatAh8W22tCA7lz8nqajFtNDMz8mmI/lP84hQ/bYmIYkGdNWluwZT6+eo7IiuXVVZXPAxFNIJV/6ktcbi/iQ8GU83T77+LLNTTTytT+TIygDFjgDvvFHtE+Qtng9rmEkxFsqm3x6Nk/ACl6EQ8k0u2V1WJk1wl9sQJcXskAVWC9Cl+2hIRxYKW66UA34xQU5dHDyaYktcJ1NYqUyJDeZ+i8f76B5yJFEzF8VFeCtI33wCLFonCEvKgv3174K67gD//ueE9g/w3qG1s3aJ62nKcbqwaNPn1ud2hV/Sz2ZRpcampcR0g+DAYRH+Sp4fKZdzLy8VrDPfgjfz+Go1xfQAofltORKRX6pLdSUnRmVseKr1npgBxxFPOStntoQ08onFEM9HKozMzlfgcDuC110Qm6osvlOsvugiYNEkUlgg20FFvUHvihNhTKlAWRZKAY8eUIEGLTHtTs1iUNYih7EOnzrLHw/S+UJlMSj+RS7qXlQH5+aFn4ORqs0DcH/zR4Bve19KlS9GjRw9kZmYiMzMTvXr1wgcffOC9fcyYMTAYDD6n888/3+cx7HY7JkyYgPz8fKSlpWH48OE4cOBAU78UIiJBD1MX4iGY8i+RHiz/qmLhBquJVh5dfg1GozYBPMXOgQPAjBlA69bADTeIQMpsBq6/XpQ6//RT4MorQ8sYpaUpA+DaWjEoVu93BIjLx48r/29GY8MZr0QRzn5TkuSbvYvzAKFB6qp+TqdSWj0UeviejBLNP21btWqFefPmYcuWLdiyZQv69++PK664Ajt27PDe55JLLsGhQ4e8p/fff9/nMSZOnIg33ngDq1atwsaNG1FVVYXLL78c7kQ40khE8Ufr9VKAGCTJA2o9TvOTb5MHHE5n8O2M1pdwImWm1BUUmZVKDMePA8uXA5dfLirxPfKIqKZWXAzMmgXs2we8/DJw9tnhPb7ZDOTm1h9QyVkH+fPMaBQZiESe4icLJ5iy2303aU9kBoNvJrOqyvd7LxgJUnwC0ME0v2HDhvlcnj17NpYuXYovv/wSp512GgDAarWisLAw4O+Xl5dj2bJlePHFFzFw4EAAwMqVK9G6dWusW7cOQ4YMie0LICLyJ3+pGAzaHnEzGkWAosdqfjKrVflSra1t2qpiiZSZ4hS/xHDkCPDWW2Iq38cf+/5d+/QBxo0TGahoDT6tVhFQHT+uFIMpKxMD5RMnlIyxwSDu11z6VjhFKNTZ9UQPpgDxHmVmKmXgy8qAgoLgs+IJlJnS1X+F2+3Gf/7zH1RXV6NXr17e69evX4+CggJkZ2ejT58+mD17NgoKCgAAW7duhdPpxODBg733Ly4uRrdu3bBp06Z6gym73Q67Koqu+KP6itPphDPSXa+D5HQ64XK5muz5KDGw3+icesNF9V5KWlBPh7Pb4XS7m6bv1NYqBR0ae/0mk9LGqqrgBonq0sNGY+gVt9Tkefvq9yoe2WxK+9UbYUYBP3NiyOOB4dtvYfjwQ3H66isYVAcjpG7d4LnqKniuvho49VTl96L5t5Cn7skBldMp1sPIB2HkQMpgCOl5E6LfOJ3i5HA0viaoslJ8jhgMIb9XcSspSXyGy995paVAXl7jvydJypors1nZIBn66jfBtkEXwdS2bdvQq1cv1NbWIj09HW+88QZO/eNDY+jQobjmmmvQpk0b7N69GzNmzED//v2xdetWWK1WlJSUICkpCTk5OT6P2bJlS5SUlNT7nHPnzsWsWbPqXH/06FGfICuWXC4XysrKAADm5nK0hyLGfqNvhpoaGP44OCNlZEBq6il26raUl8PwR9Ulj8EAFxD7viNJMJaWivMWCzxBHKU0lpV5ByEep7PhQYvHozy+2QxPhEfojeXl3iOkHnkQFIcMVVUwVFUBADxut1JtKwr4mRNdxuPHYd2wAdZPPoF1wwaYjh71ud3RvTtqL7sMtksvhbtDB+WGI0di2zC3G8YTJ+qsm/JkZ/uW+w5SvPcbn89PSWo4e+JwwPhHWXrJaoUUh683bB6P6Dd/BENSZSWkxopvOJ0wHjsm7p+cDEn1uaunflMZ5FowXfy1u3Tpgu+++w4nTpzA6tWrMXr0aGzYsAGnnnoqrr32Wu/9unXrhrPPPhtt2rTBe++9hxEjRtT7mJIkwdDAl+K0adMwadIk7+WKigq0bt0a+fn5yMzMjM4La4Qc8ebn58MS5/NFqemw3+hcWZmSXWnRQtu54PLeIACQmwvnH4FNTPuOupJhcrI4ot0Ys1kZ/GdlNbzOTM56AUB6uphmEgn1c8fzNCazWXnfCgqi+jr4mRMhtxuGzZtF5umjj2DYsgUGVcAipadD6t8fnksugTR4MAwnn4wUACFuYx0dLVooGSpATPcLdUPtP8R9v0lLU/ZSyswUnzf1qahQDsRkZ0e+mW28yc4WFR8B8T40Vt1P/l4CxGe+KvjSU7+xBrnmWRffGklJSejYsSMA4Oyzz8bmzZvxxBNP4Omnn65z36KiIrRp0wa7du0CABQWFsLhcKCsrMwnO1VaWorevXvX+5xWqzXgm2SxWJr0j2c2m5v8OSn+sd8EweMRg/qm3hPF41EqzGn9hZqc7Lt43GKJfd+RJCWATE4OLpjMyFACMPn9q09NjXJ7enrkwWpKivLc8t478cpiEa8hzMFvQ/iZE6KSEmDNGuCDD4C1a8VBFrUePYBLLgGGDoWhd28YkpK0rwgGiD6UlCT+z5KTI177E9f9JjVVTCmWNfQa3G7l9oyM5ldN02IRn6M1NeKy293w55DL5ft++X1H66XfBPv8ugim/EmSVO9Uu2PHjmH//v0oKioCAPTs2RMWiwVr167FyJEjAQCHDh3C9u3b8dhjjzVZm4lIRxwOMXiRMxh/BBKwWJQj+LEIsNQV6fSwoNa/PHpTfDEFW8lPzb9EekPZJvWC+Gi8x1qWkI8mue3NodKaHjmdoly5HEB9953v7dnZwODBIoAaPBg46SQtWhmcpCR9fH5pTT44oS55Hoge9hXUg9RUJZiy2eoPptxu360tEuAzS/Ngavr06Rg6dChat26NyspKrFq1CuvXr8eaNWtQVVWFmTNn4uqrr0ZRURH27NmD6dOnIz8/H1dddRUAICsrC7fccgsmT56MvLw85ObmYsqUKejevbu3uh8RNSPV1WLKhXrev8cjMjTqgzT5+dEfMOihJLqa+kuqqdZuhRNMGY3i/bLbxaDE6Qwc+KkWKXsHOpFST4eL14p+LpfS3+N1mmK8kSTgxx+BdetE5mn9et+pS4AoWT50qAigzj2Xf5t4ZLGIQEouVBMoUGpuVfzqIxejcLuVMvGBPqPV6zljkEXXgub/2YcPH8ZNN92EQ4cOISsrCz169MCaNWswaNAg2Gw2bNu2DS+88AJOnDiBoqIi9OvXD6+88goyVJvGLVq0CGazGSNHjoTNZsOAAQOwfPlymBIg2iWiIEmSKNEqHxkDxIe7XFXJP5ioqgpuPU8o9BZMqb/4myrrEk4wBfhOSaytDRxMxeL9TYTMFMuix15pKfC//wHffy+yTp98Ahw86Huf/HyRdRo6VPz8o+owxbGkJCUr5XAEDpYYTCmSk8UBTbnMfqBgSR1MJcj7pfmn7rJly+q9LSUlBR9++GGjj5GcnIwlS5ZgyZIl0WwaEcULt1ssmlaXMfUvTiCXvparDtXWikFotAaf6qkgJpM+BrVaBArhBlMpKcp+JTabmEfvL1bBlDyVJ54zU7J4XJuiBzabCI4OHBAn+fzOnSKIOny47u9YrcBFFwGDBonT6ac33yleicp/vyn/wb886wHQz+e+llJSlHVmgab6+U/xS5D3KzFeBRE1Xw6HCKTkzJPBINYn+H+Iy1PJ0tKUMr/V1aKSUDQ4ncpUKz1kpWTytIummuYXyoa9akajchTY5Qoc6KqLaURziqa8HxYzU4mtvBzYsQP45Rfgt9/E6ddfxc8GtlIBID5XOnYUhSN69AB69wYuuCBhpilRPdSfM4HWTakP8CRIliUi/lP9/KdGJuAUP4DBFBHFM4dDlGNVrxfJyWn46HxqqthcUd40MFqVl/Q2xU9mNPquNYo1ddGPUNc0paQoAxb/7FQsi3vIwZQk1b8uQs8YTPmqrQV++gnYvh3Ytk35uX9/w7+XkgK0bg20aqWc2rUTwdNpp/mUb6ZmwmQSnwfyzAb/dUCc4leX/1Q/dVXbBH2/+KlLRPHJ6fTdD8VqFYFUYwNhuWS5/GFfU9Pw/iHBUgdTeqqEZTIp0yqaIqCKpKpccnL9U/1iGayazcrju1z6+vsFQw6m5CmLzYXHI7JK338vAib5tGtX/X39pJOALl2A9u3FqUMH8bNdO7GGsjm9fxScpCQRBHg8YrpnVpYIvCUpdtnyeKae6qcOptxu5WBZAk3xAxhMEZEeORziS6q+fYpcLpGRkjMVVmtoA6G0NOXDvro68mBKvV7KbNZXqdemXDcV7nop9e/UN9UvlsFUPBeh8HiU/4MEGpzUUVUF/PCDUgDiu+/EWib/CnqynBygWzege3dx6tZNZJdU+1ESBSUtTalO5/GIbTeqq0XQoP4OYiAu1DfVLwELT8gS+JOXiOKS261M3ausFB+6GRlKUCXfrp7yFeoRZXmvKbtdKUYRyYe7ei69nqb4Ab6Zulivm4o0mALE38F/ql+si3vEc3n0RJri53SKwg/79ons0g8/KKd9+wL/TnKyCJR69BA/5VNhIQe3FB1Wq6jMWF6uTFNzOHw/9xMsOIhYSoo40KGe6qee4pdA66UABlNEpDfy9DtZba04ycUjyst99xoKd2pOerqS7aiqiuzLUK9T/ID4ykwB4ktWLhBSWyuCKYcjtsU94jkzFU/BVGUlsHcvsGePctq7V6xl2rdPFIFQ/+/7KygQQdOZZwJnnCFOnTvr/3VT/DOZxHeN3S6+g/wPuujtIJrWkpOVrLHNJt6fBJ3iBzCYIiI9kdcwASJAkosnAHU33TWbgby88IsFWK3iMVwu8SFf30axwdBr8Qkg/oIp9VQ/p1P8fWL9/jIzFT0ul1jH9NNP4rRzp/j588/A0aON/77VKgo/tG8PnHqqcjrlFPH/TqQlqxVo0UIc9JMLGSUnx1/Rmljzn+qn3v8xAbN4OvjkJSL6Q02NMhUtJUUs9LXZxJeW/0A9kkBKJme6APHlmJ0d+mPIVZ4AMZjV25eqOqiJ9TQ/9eNHsm5MPdWvtjb2wZQcuHs8zEyF4uhRsYZJ3sz2f/8TpccDlZCW5eQAbdsqpzZtgJNPFqfWrcVAldPzSM8MBjGzITVV9HW9HUDTC3mqHyC+w9XXJxgGU0QUe/KmugaDmCpRX8AhF4UARKBjMIgvrJQUEVRVV4vrcnKiU+RBLpPu8YjHz8wMPRjS83opwPf1xENmCvCd6ldd7TutM1bBqtks/pZud93yx3oml2t2OETgaTD4noxG8drCfT0uF3DoEJK+/hrGQ4dEpklexxRoI1tA/F916SJOXbsq59u3j96+bkRaMxoTMssSNeqpfrIEnOIHMJgioqZQXq5kb8rKAk/Xqa1VjrJbrb5T7uSgSr1fRTTIjysvlK2u9i3HHYx4CKYMBvH63O7YBgnqYCqSoMdkEn9/p9P3MWP5/vpPh9TyC9/lEmuJfvkF+P134NAh5eehQ+LARE2N6K81Nb4LuwMxmcTBCfUpNVW8x0lJysliEY937JjIOh09Cpw4AQuA/Poeu0MH4PTTxVom+WfbtvrL0BJR01JP9ZMlaPDJYIqIYks+Yi6z28Ug0H8DTPURrKbcHDMtTXluuUx6KAGHnotPyORNaT2e2JZtj2TDXn8pKUoALku0YMrjEWuJvvxSZHp27hSXf/217muPhNstMn1yti9EksEAd5s2MJ52GozduinrmLp2jc4ebUSUmNRT/eTLCYjBFBHFVqABXEWFUgACEANH9T5NTXn0ymRSphF6PKHNgVevl4rlFLRIye2S9/uIlUg27PWXnOzbdwyG2Aar/kUoYhG4HT8uAqdvvwU2bRLnjx8PfN+UFJH1adUKKCpSToWFYl2RPA3W6RT3zc8Xa/4kSTnJe1DJU2TlU02NOMn/d+qT/Fj5+SKDnJ8PV3o6jpSVoUWLFjCGW6SFiJofdTBlNifkFD+AwRQRxVJtrW+QlJQkBnGSBJw4IQZsgHZZKZkcTAFKGddg6H2Kn6wpKvpFa72UzGxWpvoBou/EcopirN6j2lrggw+Af/8bePdd340rAdH3zjlHlPnu0kWU+u7cWQRRjQW+lZXKwu7c3NgdhIhmloyImg+LRXzG1daKNckJisEUEcWOOrOQmansNSGXI6+sFGs35AGm0Rj9dVHBkHevlzcYDFY8TPED4jOYAkRwIA/kYx2sRrM8utMJfPgh8MorwFtv+VayKiwEzj0X6NcPuPBCsc4o3GyP3sqiExH5y8nRugUxx09fIoqNmhplsJeUpBw1z85W9puprPQ96i1PXWpqBoNonzzVz24PbvCu5/2l1NQZjliVR49FMJWWprzHsQ6yoxFwHjgAPPMM8NxzolCE7KSTgMsuA4YPFxkoubRypEdq1cFULNfCERFRvRhMEVH0SVLdrJQsKUlUzJOP1suZILmynlbkYEpuU2PBkcfjGyzquZS2aqBtiKdgymhUpoI2BXkT51AyUx4PsHYtsHQp8M47SrBaUABcdx1w7bWiJLj/+y4XO4lkDZvczkhKnxMRUUQYTBFR9FVVKYPH5OS6U+DS00XAos5KpaRoe3Q9Odl3ql9j++HEyxQ/oGmm+UVrw14tyVUP5eINDQU6NTXA8uXAokWihLmsTx/gjjuAq65S1gieOCFuk8uPV1eL56iqCj87Je+HBXCKHxGRhvgJTETR5fH4FpQINFiUN949ckQZEGpReMK/TVarCKTcbrGmq6EgKV6m+AG+wU08Zaaamtms/F3d7sDB1JEjwFNPAX//u9iPCRB9fPRo4PbbRclwmST5rpfKzBTvjVyEJZLsFNdLERHpAj+BiSi6KiuVACk1tf6Bntks1k9VVIislB5KLicnK9MOa2sbDqbkSn6xLtkdDarBepNM89NrifjGqINAl8u3T/7yC7BggchGyX2kXTtg0iTgz38OfDCgpkZ5X6xWpZ/Ie5vJwVZjWdBAGEwREekCP4GJKHqcTjGABESQkZHR8P1TUvS1iZ+6tLTNVv8ULLdbGcxaLPpfr2IwKAFOrKv5RWPDXq0Emg65cycwezbw0ktKVu/ss4F77gFGjKg/kAmUlZKlpytT/WpqxOVQs3kMpoiIdIGfwEQUHfLeUXJWKpwBotaMRpFBsNvFYNrpDJwxi5f9pdTUG/fGQjQ37NWKOijZvh148klg1SqlTw8dCkydKtZFNRYwVlf7rhtU9yOj0Tc7VVUVenaKwRQRkS7wE5iIoqOqSikoYTaLYCoepaQo62ZstsDBVDytl5LJwZQkKcFBtCTCeilAtH3XLjGd7513lOuHDwcefBDo2TO4xwlm3WCk2Sn5f81ojN9plURECYCfwEQUOZfLd/CYnR2/U73UU/3q28BXDqYMBn2s9QpGLPeaSoRg6tAhUYWvXz8lkBoxAvjmG7HxbrCBFOCblapv3aCcnQKU7FSwPB7l8ZmVIiLSFD+FiSgykgSUlflO79N7QYaGqKf6uVx1p/o5HErwoPf9pdQYTAVWWQnMny9O8nq/wYPFmqgBA8L7+1ZXi5+NrRv0z05lZASXZVJP8YuXYJ6IKEExmCKiyFRX+07va6zoRDxITlayT7W1yoC1utp3M+J4meIHxDaYisc9ptxu4NlngZkzgcOHxXXnny+m851+urjsX9Ev2MeV34+kpIbfD6NRZK7kgMpuD64gC9dLERHpBqf5EVH4XC7fimXxPL1Pzb+qn5x9Ky9XMnBJSdrvjRUKZqYUO3cCF10kpvUdPgx07Ai89hqwaZO4XqYOWoIVatZIHZCrN7EO9jkYTBERaYrBFBGFJ9Gm96mZTMprcbmA0lIRVMnS04G8vPgKHJsqmNJzMQS3WxSXOOMM4IsvRBb1ySeBH34Arr5a/D3995oKlTogCiaYUv/PqKtENoTBFBGRbvBTmIjCk4jT+9SSk5XBrRwsGAxATo5v5ipeNPfM1M8/i811N20SlwcNAp57Djj5ZN/7qYOTSIOpYAIdo1HcT16fJ0mNB+lyu/yDPyIianI6PoRIRLomL9YHEmd6n5r/2hWLBWjRIj4DKcA3mIpVaXQ9btgrSSL7dPrpIpDKyACeeQb48MO6gRTgGwCFs8FxOFkjOTslSY1P9ZMk5TmYlSIi0hw/iYkodOoBncWSONP71EwmURygpkb8zMrSX6AQiqbITOktS1JdDdx6q9h4F6g/G6UmZ3vc7tAzU/6BTrD9JSlJOTjhcDT8/6QO8BhMERFpjp/ERBS65jKgy86O/yBKFqtgSq9T/H79FbjqKmDbNtFHFy4Exo8P7m9pNitV+Tye4NeBud1K1i+UKoChrJvieikiIl3hJzERhS7UdSHxLBECKSB2wZT6sfRSfOKDD4BRo4ATJ4DCQuA//wEuvDD43zebldL4LlfwmddQi0+on89gEIEYgykioriik28+Ioor3DQ0PsnBTqIGUx4P8MgjwGWXiUCqVy9g69bQAikg/CIUkRxkkAM2j6fhtVoMpoiIdIXBFBGFjgO6+CRn2WIVTGk5zc9mA669FpgxQ2R4xo4FPvkEKC4O/bHCDaYiOcgQ7FQ//u8REekKP4mJKHQszRyfEjUzdfgwcMUVwFdfiSDmH/8QhSfCFWlmKpz/C/9gyr+apP9zmEyJMwWViCiOMZgiotDJA0wO6OKL/7qpaAQ/WgdTP/wgpvXt2QPk5gJvvAFcfHFkjyn3a3V1vsZIkjI9L5ypr+rfqS8zpS5wwawUEZEucJofEYXG5QqvYhlpLxZFKNTre5o6mPr4Y6B3bxFIdewIfPFF5IGUTM4sBbvXVLjFJ2Ty5r3yYwXaC6y2NrLnICKiqGMwRUSh4ZqN+BWLYEqrzNS//gVccglQXg5ccIEIpDp3jt7jy31bnXFqSDQqXKqn+gXavLe6Wjlf3zRAIiJqUgymiCg0DKbiVyIEU5IEPPwwcMstoi9edx2wbh2Qnx/d5wl13VQ0Klw2VITCbleeIymJmSkiIp1gMEVEoWlOe0wlmlgGUwZD7NfPeTzAXXcBDz4oLk+fDrz0EpCcHP3nCjWYinZmyj+YqqpSzqenh/f4REQUdRwJEVFomJmKX7EMpmKdlXI6gTFjgJdfFpeffBKYMCF2zxduZspkCv+9MJvF73o8vsGUy6VsImwyxSZ4JCKisHAkREShkQeNZjMr+cUb9SA/UIGDcDRFMFVdDVxzDfDBB6LfrVgBjBoVu+cDQgum3G7lfYj0AENSkig04fGI5zWbfddKpaVF9vhERBRVDKaIKHgszRzfop2ZaooNe48fBy6/XBSYSEkBVq8Ghg6NzXOpGY1KlqixYCrSSn5qFotStc/hEG2oqRGXDQYgNTWyxycioqjiaIiIgsf1UvEtlsFULDJTR44AAwYA27YB2dnAe++JUuhNxWwWAY18EKG+TGw0ik/I/Cv6eTzKAYzUVO02RiYiooA0/1ReunQpevTogczMTGRmZqJXr1744IMPvLdLkoSZM2eiuLgYKSkp6Nu3L3bs2OHzGHa7HRMmTEB+fj7S0tIwfPhwHDhwoKlfClHii+agkZpePAVTx44BAweKQKqoCPjss6YNpADfbFtD2aloHmRQB1N2O6f4ERHpnObBVKtWrTBv3jxs2bIFW7ZsQf/+/XHFFVd4A6bHHnsMCxcuxFNPPYXNmzejsLAQgwYNQmVlpfcxJk6ciDfeeAOrVq3Cxo0bUVVVhcsvvxzuYDdbJKLgsPhEfFNX3ItGMBWrDXvLyoBBg4D//Q8oLAQ++QTo1i16jx8sdR9v6Pskmv8XBoNyoMLlUp43OZn/c0REOqR5MDVs2DBceuml6Ny5Mzp37ozZs2cjPT0dX375JSRJwuLFi3H//fdjxIgR6NatG1asWIGamhq8/EdFp/LycixbtgwLFizAwIEDceaZZ2LlypXYtm0b1q1bp/GrI0owDKbiXzSDqVhkpsrLgSFDgG+/BVq0AD7+GOjSJTqPHapgilBIUvSLsqizUzJmpYiIdElXoyG3243//Oc/qK6uRq9evbB7926UlJRg8ODB3vtYrVb06dMHmzZtwtixY7F161Y4nU6f+xQXF6Nbt27YtGkThgwZEvC57HY77HKpWQAVFRUAAKfTCWegnedjwOl0wuVyNdnzUWLQtN/U1IjBo8kUXLlo0hWn0wmXxwOXXGo70j6kfgy3O/LHq6yE6dJLYdy8GVJeHlxr1gCdOkX+uOGSJOW5bTbAaq17H5dLKWNuNkenrQZD3amDRqNm7wO/qygc7DcUDj31m2DboItgatu2bejVqxdqa2uRnp6ON954A6eeeio2bdoEAGjZsqXP/Vu2bIm9e/cCAEpKSpCUlIScnJw69ykpKan3OefOnYtZs2bVuf7o0aM+QVYsuVwulJWVAQDMPMpPQdKs37jdMB49CgCQrFZIXAgfd1wuFyoqKmBwu2EymeAxmSLKpBgqKmD4o9KcR5ICZ1SCfazqauTeeCMsX38NT3Y2jr78MlyFhaIIhVYkCcZjx8T5ykp4An2x2mwwlpeLu2dkQIrGQQaXS3leAFJWFiQN3wd+V1E42G8oHHrqN+olRQ3RRe/u0qULvvvuO5w4cQKrV6/G6NGjsWHDBu/tBr8ve0mS6lznr7H7TJs2DZMmTfJerqioQOvWrZGfn4/MzMwwX0lo5Ig3Pz8fFi7mpyBp1m/sdmVaV3o60ET/JxQ9TqcTxhMnkJuWJr6k8vIiK2luNoty5QBQUBD+1E+7HaYbb4Tx668hZWXBvWYNcs46K/x2RZMkiayb0SimHfqrqFBed25u9DbUNRqV523ZUtM93fhdReFgv6Fw6KnfWAPNRghAF8FUUlISOnbsCAA4++yzsXnzZjzxxBO49957AYjsU1FRkff+paWl3mxVYWEhHA4HysrKfLJTpaWl6N1A5Ser1RrwTbJYLE36xzObzU3+nBT/NOk3druyMD4lhdX84pTJYvH2H5hMkf0d1b+fnBzegN/tBkaPFkUm0tNh+PBDWM47L/w2RVtKiuj7gHi9/hlZdcGI1NTo7bfVooWo5JeWFlHGL1r4XUXhYL+hcOil3wT7/LqcpyNJEux2O9q1a4fCwkKsXbvWe5vD4cCGDRu8gVLPnj1hsVh87nPo0CFs3769wWCKiELE4hOJIZrl0eXfV1cJDIUkAbffDrz+uggY3nwT0FMgBTRehEKe+mcwRHfjYqtVZLqCPDJKRETa0HxENH36dAwdOhStW7dGZWUlVq1ahfXr12PNmjUwGAyYOHEi5syZg06dOqFTp06YM2cOUlNTMWrUKABAVlYWbrnlFkyePBl5eXnIzc3FlClT0L17dwwcOFDjV0eUQLjHVGKIRTAV7vq56dOB554Tv//vf4sNevXGP5hSZ4k8HqV0Of8niIiaJc2DqcOHD+Omm27CoUOHkJWVhR49emDNmjUYNGgQAGDq1Kmw2Wy48847UVZWhvPOOw8fffQRMjIyvI+xaNEimM1mjBw5EjabDQMGDMDy5cthiuZRQqLmTg6mIixaQBrTSzC1YAEwb544//TTwIgRkbUlVhrauJcHGIiImj2DJEmS1o3Qg4qKCmRlZaG8vLxJC1AcOXIELVq00HxeKMUPTfqNxwPI1TGtVlG4gOKO0+nEkf370cJkEn0nM1MUEwlHJH1i+XLgz38W5+fNA/5YH6tLLhdQWirOJyeLqXey6mqxLxYAZGUl7F5Q/K6icLDfUDj01G+CjQ10uWaKiHRGXRKaX4rxLVqZqXA37H3/feDWW8X5yZOBqVPDb0NTUG/EK0/pA8TeUlVVymX+XxARNUuaT/MjojjA4hOJw2gUhR+Apg+mvv8euPZapYLf44/Hx5RReZNql0u8d1VVgHr/EbOZwRQRUTPFURERNY7BVOKQ9y8CmjaY+v134PLLRSDSvz/w7LPxEUgBos/LgdTRo76Z2qQkICcnfl4LERFFFUdFRNQ49eCRwVR8Uw/6myqYqq4Ghg0DDhwAunYFXnstvjI56j6v/l/IyBAnIiJqtjgqIqLGyZkpozH8MtikD+o9oaIVTDVUOdXtBm64AfjmGyA/H3jvPZHJiSf+BxBMJvEadLCZLhERaYvBFFEi8HiAEydE0JOdHd1BnsejDJzjKZtA9ZMD4qbITN17L/DWW6Li31tvAe3bh/+cWrFaRQAqSUBKiqjcx4MKREQEBlNE8c/jEes45OzR8eMiAxCt6XhcL5V4ohFMqSvb1RdYPP202E8KAJ5/HujdO/zn05LJBBQUiPeLBxSIiEiFh9aI4pnb7RtIAWLAd+xY5BuyyrheKvFEozx6Y5mpjRuBcePE+YceAq6/Przn0QuTiYEUERHVwWCKKF653SJokgMp9WDP7RYZqmjsyW23K+c5mEwMsQ6mSkqAkSNFP7z+euCBB8J7DiIiIp1jMEUUj/wzUiaTmNqXm6sUA3A4gLKyyJ7H41GCKZOJC+4TRTSDKf9AyuUCrrsOOHQIOO20+CqBTkREFCIGU0Txxu2G8fhxZc2K2SwCKZNJnHJzlcFrbS1QURH+c9ntSnYrOTmydpN+xDKYuv9+YMMGID0dWL0aSEsL7/GJiIjiAIMponhTVuYbSOXl+ZamtlhEQCWrqhL7/ITDZlPOp6SE9xikP+oAKJypoJKk/J76sd54A3jsMXH++eeBLl3CbyMREVEcYDBFFE88HjF9D1Cm9gXa48dqFSXSZeXlvkUqgn0uTvFLTJFmpgLtMbVrFzBmjDg/aRLwf/8XdvOIiIjiBYMpongiB1KAyBQ1tNdNaqqYaiWrqQntuWprOcUvUUUzmDIaRd+6+moxpfTCC4F58yJvIxERURxgMEUUT9SV9YLJFEUaTMk4xS+xRDuYGjcO2LYNaNkSeOUVVn0kIqJmg8EUUTxRZ6aCCaaMRiWr5PH4BkgN4RS/xBbNYOrVV4Hly8VjrloFFBdH3DwiIqJ4wWCKKF54PMoGuhZLw1P81FJTlfPBZqfUU/yYlUo8kQZTcgGUPXuAu+4S5//2N6Bv30hbRkREFFcYTBHFC1VWSgplGlVysjJ4rq0NbvCsruLH9VKJR73vU7iZKYcDuOMOUSny4otFSXQiIqJmhsEUUbxQB1OhTrtTZ6fUgVIgnOLXPMgBdrjB1GOPAf/7H5CTA7z0UuCqkkRERAmOwRRRvAi1+IRaKFP9WHiieYgkmFq3Dli6VJx/9lmgVavotYuIiCiOMJgiigfhrpeSmc1KAOZ0Ko8VCKf4NQ9yH1JvwBuMw4eBO+8U50ePBkaMiH7biIiI4gSDKaJ4EGoVv0CCyU5xil/zEU4RCo9HBFBHjgBdu4qiE+r1V0RERM0MgymieBCNYCo5WRn42myBsxGc4td8hBNMLV4MfPih6EtLlwJpaTFpGhERUbxgMEUUD9TBlNUa3mMEs+eUeoofg6nEFmowtW0bMG2aOD9zJtC5c+jTTYmIiBIMvwmJ9E6SlGDKbI5sAFvfVD+XCygr853iF0r5dYo/6n7U2Jopux248UbRDy+7TJz3fwwiIqJmyKx1A4ioEdHISql/32QSm67a7eKxa2rqrqHi9K3EF0pmasYMUQa9RQvgn/9UposymCIiomaO34REehdJSfRA1Nmpo0d9AymjEcjMBNLTI38e0rdgg6kNG4D588X5Z58VAVWgxyAiImqGmJki0jv/4hPh7AuklpoKVFb6Xmc0imxUejqrszUXwQRT5eXAn/4kpgHecgtwxRW+6+oYTBERUTPHYIpIzyRJ2RPKbBZT9CINpkwmUYiitlYETunpIpDiwLh5CSaYmjAB2LcPaN8eWLSo7n3ZZ4iIqJljMEWkZw6HUhwgmns+5eSIxw5nA2BKDOoMZKBg6j//AV58UfSPF18EMjLq3tdkim0biYiIdI7BFJGeRbP4hJrBEN3Ho/jTUGbq0CHg9tvF+WnTgN69A9+XgTgRETVz/CYk0rNoF58gkhkMSnZKHSBJEvCXvwDHjwNnnQX87W++v8dgioiIyIvfhER6pV4vZTJxShVFnxwMqQOk5cuB994TwfsLL9Tdb8ztrvv7REREzRS/CYn0yulU1ktxSh7Fgn8wtW8fcNdd4vxDDwGnnVb3d+T7qjNbREREzRSDKSK94hQ/ijV1ZsntFuXPKyuB888HpkwJ/DtyMMWsFBEREYMpIt2Sp/gBDKYoNtQB0dKlwLp1QEoKsGJF/dNKGUwRERF58duQSK/kSn5Go9hjiija5IBo717g3nvF+blzgc6dA9+fxSeIiIh88NuQSI/cbmXg6l8AgChajEbRzyZOBGpqgD59xEa99WEwRURE5IPfhkR6pN5filP8KFaMRuC554CvvwZSU4F//avhIIkb9hIREflgMEWkR+r1UsxMUazs3g3MmyfOz5kDtG/f8P2ZmSIiIvLBb0MiPWJmimLN4wHuvFNUjbzgAuDPf278d7jHFBERkQ9+GxLpkXqzXg5aKRaeeQb47DMgORl4/HFlT7OGMDNFRETkg9+GRHqj3qyXWSmKhf37galTxfn77gPatAFcrsZ/j8EUERGRD34bEukN10tRLEkSTOPGic15e/UCbr1VXK/ud/VhMEVEROSD34ZEesP1UhRDKatXw7hmjehby5aJaX6ACJTUa6ICYTBFRETkQ/Nvw7lz5+Kcc85BRkYGCgoKcOWVV2Lnzp0+9xkzZgwMBoPP6fzzz/e5j91ux4QJE5Cfn4+0tDQMHz4cBw4caMqXQhQdzExRrBw+jKy//U2cf/BB4JRTfPtYY1P95GDLYGAwRUREBB0EUxs2bMC4cePw5ZdfYu3atXC5XBg8eDCqq6t97nfJJZfg0KFD3tP777/vc/vEiRPxxhtvYNWqVdi4cSOqqqpw+eWXw93YkVYiPZEkJZiyWMSglShKTBMnwnjiBKTTT1fWTJnNyh0amuonSUqwpf4dIiKiZkzzb8Q1a9b4XH7++edRUFCArVu34uKLL/Zeb7VaUVhYGPAxysvLsWzZMrz44osYOHAgAGDlypVo3bo11q1bhyFDhsTuBRBFE7NSFCtvvgnj6tWQTCa4nnkGFrl/qftZQ8EU+yYREVEdmgdT/srLywEAubm5PtevX78eBQUFyM7ORp8+fTB79mwUFBQAALZu3Qqn04nBgwd7719cXIxu3bph06ZNAYMpu90Ou93uvVxRUQEAcDqdcAazEDsKnE4nXC5Xkz0fxYHqamXQajAEHNyy31DIKipgHj8eBgAVt98OS7duSt9SZ0MlCUhPD/wYQfRNSkz8zKFwsN9QOPTUb4Jtg66CKUmSMGnSJFx44YXo1q2b9/qhQ4fimmuuQZs2bbB7927MmDED/fv3x9atW2G1WlFSUoKkpCTk5OT4PF7Lli1RUlIS8Lnmzp2LWbNm1bn+6NGjPkFWLLlcLpSVlQEAzJw2QwAMJ07AUFsLAPAAYgDrh/2GQpX54IOwHDwIZ5s22HvTTcg+etSn7xgrKrzBkQcIOL00mL5JiYmfORQO9hsKh576TWVlZVD301XvHj9+PP73v/9h48aNPtdfe+213vPdunXD2WefjTZt2uC9997DiBEj6n08SZJgqGfNybRp0zBp0iTv5YqKCrRu3Rr5+fnIzMyM8JUER4548/PzlSk31Lx5PEBamhjMFhYGHNSy31AoDFu3wvT88wAA95NPIruoqG7fMZsBm02cz8kJPI1Pkhrtm5SY+JlD4WC/oXDoqd9Yrdag7qebYGrChAl4++238emnn6JVq1YN3reoqAht2rTBrl27AACFhYVwOBwoKyvzyU6Vlpaid+/eAR/DarUGfJMsFkuT/vHMZnOTPyfplMcjKqQZjaJsdQNl0dlvKCguFzBunOhbo0bBNHQozEeO1O07qam+lfz8+5XHI4Ini6XRvkmJiZ85FA72GwqHXvpNsM+veTU/SZIwfvx4vP766/jvf/+Ldu3aNfo7x44dw/79+1FUVAQA6NmzJywWC9auXeu9z6FDh7B9+/Z6gyki3VHPzeVglaLh738HvvkGyM4GFi6s/36NlUdn8QkiIqKANM9MjRs3Di+//DLeeustZGRkeNc4ZWVlISUlBVVVVZg5cyauvvpqFBUVYc+ePZg+fTry8/Nx1VVXee97yy23YPLkycjLy0Nubi6mTJmC7t27e6v7EemeerNeDlgpUvv3Aw88IM4/+ijQsmX9RSMaq+jHYIqIiCggzYOppUuXAgD69u3rc/3zzz+PMWPGwGQyYdu2bXjhhRdw4sQJFBUVoV+/fnjllVeQkZHhvf+iRYtgNpsxcuRI2Gw2DBgwAMuXL4fJZGrKl0MUPmamKJr++legqgro3Ru49daG7ytPL/V4AgdT6kCffZOIiMhL82BKkqQGb09JScGHH37Y6OMkJydjyZIlWLJkSbSaRtS05AGr0QjwIABF4q23gDffFIUlnn5a9KnGWCyA3S4CKnn9nkxdEp1VuYiIiLw0XzNFRADcbjGABTiNiiJTVQVMmCDOT5kCqLaZaFB9U/08HtE//e9DREREDKaIdIHTqChaHnlErJdq1w6YMSP431NnnNTBFPsmERFRvRhMEekBF/hTNPz0k1K174knRMnzYNWXmWLfJCIiqheDKSI94NF/ipQkiel9Tidw+eXAsGGh/X59mSkWRiEiIqoXgykiPZAHrCZTcMUCiPytXg2sWwdYrSIrFSp5U15A7DUlFwdiYRQiIqJ6RX3UVltbG+2HJEpsTqcycOWRfwpHdTUwaZI4f++9QPv24T2OOjvlcrEwChERUSPCDqZeeeUV/OMf//Be/uWXX3DqqaciLS0NF110EcrKyqLSQKKE53Ip5zlgpXDMni2KTrRtC9x3X/iP479uilP8iIiIGhR2MDV//nxUV1d7L99zzz0oKyvDXXfdhZ9++glz5syJSgOJEh4X+FMkfv4ZmD9fnF+8GEhJCf+x1P3P5fJdy8e+SUREVEfYwdRvv/2Gbn/sX1JbW4sPP/wQjz76KBYuXIhHHnkEb775ZrTaSJTY1MEUN0SlUEgS8Ne/ij506aXA8OGRPV5DmSkGU0RERHWEPXKrqalBWloaAOCrr76C3W7H0KFDAQCnnnoqDh48GJ0WEiU6eZofF/hTqN58E/jwQzEF74knRBGJSBiN4uTx+AZSJhP7JhERUQBhZ6aKiorw3XffAQDWrFmDLl26oEWLFgCAsrIypIayvwlRc+XxiEX+ALNSFJqaGmDiRHF+6lSgY8foPK6cgfJ4WHyCiIioEWGP3kaMGIH7778fGzZswAcffIB7773Xe9v//vc/dOjQISoNJEpoLD5B4Xr0UWDfPuDkk4Fp06L3uBYLYLfXvY6IiIjqCDuYevjhh1FVVYVNmzZh1KhRmDp1qve2d999FwMHDoxKA4kSGtdLUTh27xbBFAAsWABEcyZAoMCJlfyIiIgCCnv0lpKSgn/+858Bb/vyyy/DbhBRs8LMFIVj0iSRPerfH7j66ug+dqCgnn2TiIgooKhv2ktEIWBmikL10Uei8ITJBDz5ZORFJ/z590OTSRSlICIiojpCGr3dfPPNQd/XYDBg2bJlITeIqFmRgykOWCkYDocohQ4AEyYAp50W/ecwGEQmSu6bnOJHRERUr5CCqf/+978wqI6CnjhxAuXl5TCbzcjLy8OxY8fgcrmQlZWFnJycqDeWKKG43WKfIIDTqCg4S5YAO3cCBQXAzJmxex6zWQmm2DeJiIjqFdKh8D179mD37t3YvXs3Xn31VaSnp+Oll16CzWbDoUOHYLPZsHLlSqSlpWHVqlWxajNRYuAUPwrFoUPArFni/Ny5QFZW7J7Lag18noiIiHyEPYKbPHkypkyZguuvv957nclkwqhRo3D48GHcfffd+Pzzz6PSSKKExOITFIr77gMqK4FzzwXGjIntc6WkiKyp0ci+SURE1ICwF2ls3boV3bp1C3hb9+7dvRv6ElE9mJmiYH3xBfDCC+L8kiWxX19nMABpaSKoIiIionqF/Y2cmZmJdevWBbxt3bp1yMzMDLtRRM2COjPFYIrq43YD48eL8zffLDJTREREpAthj+BuuukmPP7443C5XBg1ahQKCwtRUlKCl156CYsXL8akSZOi2U6ixCJJSjBlNke/vDUljueeA775RqyRmjtX69YQERGRStjB1Jw5c1BaWooFCxZg4cKF3uslScKNN96IOXPmRKWBRAmJlfwoGMePA/ffL84/9JCo4kdERES6EXYwZTabsXz5ckybNg2ffPIJjh07hry8PPTt2xddu3aNZhuJEo96vRSDKarPjBnAsWNAt27AnXdq3RoiIiLyE1YwZbPZ0LFjR/zzn//EsGHD0KVLl2i3iyixsfgENea774B//lOcX7KE/YSIiEiHwipAkZKSApvNhrS0tGi3h6h5YFl0aogkARMmAB4PcO21QN++WreIiIiIAgi7mt+AAQPqreZHRI2QM1MGA2AyadsW0p+XXwY2bgRSU4H587VuDREREdUj7Hkj06dPx9VXX43k5GSMGDECRUVFMPhVJMvNzY24gUQJR5JEAQqAWSmqq7ISuOcecf7++4FWrbRtDxEREdUr7GCqZ8+eAICZM2di1qxZAe/jlgeMRKTgeilqyMMPA4cOAR07ApMna90aIiIiakDYI7kHH3ywTiaKiILASn5Un507gcWLxfnFiwGrVcvWEBERUSPCDqZmzpwZxWYQNSMsPkGByEUnnE7gssvEiYiIiHQt7AIURBQmTvOjQN58E1i7FkhKUrJTREREpGsRjeTcbjc++OAD/Pjjj7DZbD63GQwGzJgxI6LGESUkOTNlMgFGHs8gADU1wN13i/P33CPWSxEREZHuhR1MHTt2DBdddBF++uknGAwGSJIEAD7rqBhMEflxu8XeQQCzUqR49FFg716gdWtg2jStW0NERERBCvuw+P3334/k5GTs3bsXkiThq6++wq5duzBp0iR07twZ+/bti2Y7iRID10uRv99+E8EUACxcCHAzdCIiorgRdjD18ccfY9KkSSguLhYPZDSiQ4cOePzxxzFw4EBMmTIlao0kShhcL0X+Jk0C7HZgwADg6qu1bg0RERGFIOxg6sCBA2jbti1MJhOMRiOqq6u9tw0bNgxr166NSgOJEgozU6T2wQfAW2+JwPrJJwFuN0FERBRXwg6m8vPzUV5eDgAoLi7G9u3bvbcdP34cLvWgkYgEZqZIZrcDd90lzt91F3Dqqdq2h4iIiEIW9miuZ8+e2LFjBy677DJceumleOihh5CZmYmkpCRMnz4d559/fjTbSRT/JEnJTJnNzEI0d4sWAbt2AYWFwIMPat0aIiIiCkPYwdT48ePx66+/AgAefvhhfPnll/jTn/4EAOjQoQOeeOKJ6LSQKFE4HCKgAsReQtR87d8PPPywOP/YY0BmprbtISIiorCEHUwNHDgQAwcOBAC0aNEC3377LbZv3w6DwYCuXbvCzClMRL7sduW81apdO0h7d98t9pa68ELgxhu1bg0RERGFKWoRj8FgQPfu3aP1cESJx+FQzjMz1Xx9+CGwerXYtPnvf+d0TyIiojgWdgGKli1bYtSoUfjXv/6FvXv3RrNNRIlHkpRgymwWA2lqfux2YPx4cX7CBKBHD23bQ0RERBEJOzN17bXX4uOPP8aqVatgMBjQvn1779S//v37IycnJ5rtJIpv6qwUp/g1X48/Dvzyiyg6MWuW1q0hIiKiCIWdmXryySexY8cOHDx4EM8//zx69eqFd955ByNHjkSLFi1w7rnnBvU4c+fOxTnnnIOMjAwUFBTgyiuvxM6dO33uI0kSZs6cieLiYqSkpKBv377YsWOHz33sdjsmTJiA/Px8pKWlYfjw4Thw4EC4L48outTrpTjFr3nasweYPVucX7CARSeIiIgSQNjBlKyoqAh/+tOf8M9//hNPP/00Bg0aBI/Hg61btwb1+xs2bMC4cePw5ZdfYu3atXC5XBg8eLDPJsCPPfYYFi5ciKeeegqbN29GYWEhBg0ahMrKSu99Jk6ciDfeeAOrVq3Cxo0bUVVVhcsvvxxutzvSl0gUORafoLvuAmprgb59geuv17o1REREFAVhT/PzeDz4+uuvsW7dOqxduxZfffUVAOC8887DrFmzvJX+GrNmzRqfy88//zwKCgqwdetWXHzxxZAkCYsXL8b999+PESNGAABWrFiBli1b4uWXX8bYsWNRXl6OZcuW4cUXX/Q+78qVK9G6dWusW7cOQ4YMCfdlEkXO41E26zWbAWPExzAo3rz7LvD22+Lvz6ITRERECSPsYCovLw+VlZXo3r07BgwYgGnTpuHiiy9GampqRA0qLy8HAOTm5gIAdu/ejZKSEgwePNh7H6vVij59+mDTpk0YO3Ystm7dCqfT6XOf4uJidOvWDZs2bQoYTNntdthV2YKKigoAgNPphFMe+MaY0+mEy+VqsucjjdTWKsFUUpJyPkzsN3HGZoP5r3+FAYD7r3+Fp1OniPtAuNh3KBzsNxQO9hsKh576TbBtCDuYKi8vR3JyMoqLi9GqVSu0bt064kBKkiRMmjQJF154Ibp16wYAKCkpASCqB6q1bNnSW0WwpKQESUlJdYpetGzZ0vv7/ubOnYtZARaAHz161CfIiiWXy4WysjIA4L5cCcxQWQnDH9NWPW63bzGKMLDfxJeM+fORsXs33IWFKL39dkhHjmjWFvYdCgf7DYWD/YbCoad+o15O1JCwW3nkyBF8/PHHWLduHZ588klMmjQJRUVFGDhwIAYNGoSBAweisLAwpMccP348/ve//2Hjxo11bjP4TYuRJKnOdf4aus+0adMwadIk7+WKigq0bt0a+fn5yGyiheFyxJufnw+LxdIkz0kaSU4WPwsLI57mx34TR37+Gea//x0AIC1ciPy2bTVtDvsOhYP9hsLBfkPh0FO/sQa5xj2iaX4jR47EyJEjAQC//vor1q5di9WrV2P06NEwGAxwuVxBP96ECRPw9ttv49NPP0WrVq2818sBWUlJCYqKirzXl5aWerNVhYWFcDgcKCsr88lOlZaWonfv3gGfz2q1BnyTLBZLk/7xzGZzkz8nNSGPR/y0WMQpSsUn2G/igCQBEyeKTOSQITBfd50u1kqx71A42G8oHOw3FA699Jtgnz/ilfBOpxMbNmzA8uXLsWLFCqxfvx6SJHnXPDVGkiSMHz8er7/+Ov773/+iXbt2Pre3a9cOhYWFWLt2rfc6h8OBDRs2eAOlnj17wmKx+Nzn0KFD2L59e73BFFGTUE/pY0n05mXVKmDdOhFAP/WULgIpIiIiiq6wM1MLFizAunXr8Nlnn6Gmpgapqam48MILMXfuXAwYMABnnnlmUI8zbtw4vPzyy3jrrbeQkZHhXeOUlZWFlJQUGAwGTJw4EXPmzEGnTp3QqVMnzJkzB6mpqRg1apT3vrfccgsmT56MvLw85ObmYsqUKejevXvQVQWJYoIl0Zun8nJAnkZ8//1Ax47atoeIiIhiIuxg6r777sM555yDSZMmYcCAAejdu3dY6bilS5cCAPr27etz/fPPP48xY8YAAKZOnQqbzYY777wTZWVlOO+88/DRRx8hIyPDe/9FixbBbDZj5MiRsNlsGDBgAJYvXw6TyRTuSySKHDNTzdMDDwAlJUDnzsDUqVq3hoiIiGLEIEmSFM4vVlZW+gQz8a6iogJZWVkoLy9v0gIUR44cQYsWLTSfF0ox4PGIATUg1ku1aBGVh2W/0bmtW4FzzxV//3XrgAEDtG6RF/sOhYP9hsLBfkPh0FO/CTY2CHvNlDqQ2rlzJz7//HNU/1H+mYjAKX7NkdsN3H67CKSuv15XgRQRERFFX0QFKF544QW0atUKp556Ki6++GLs3LkTADBy5Eg8++yzUWkgUdziFL/m5+mngS1bgMxMYOFCrVtDREREMRZ2MPWf//wHY8aMwVlnnYWnnnoK6tmCZ511Fl599dWoNJAobjEz1byUlADTp4vzc+aIPcWIiIgooYUdTM2dOxd//vOf8fbbb+O2227zue2UU07BDz/8EHHjiOKWxwPI+6wlJbEsdnMwaZKo4tezp5jqR0RERAkv7GDqxx9/xHXXXRfwttzcXBw7dizsRhHFPXVWilP8Et+HHwL//jdgNALPPAOwiigREVGzEHYwlZqaivLy8oC3HTx4EDk5OWE3iijucYpf81FTA9xxhzh/113AWWdp2x4iIiJqMmEHUxdccEGdtVKy5cuX19k3iqhZqa0VPw0GZqYS3cMPA7t3A61bAw89pHVriIiIqAmFvWnvgw8+iAsvvBDnnnsuRo0aBYPBgNdffx1/+9vfsGHDBmzevDma7SSKHw6HWDMFiKwU10slrm3bgPnzxfmnngLS07VtDxERETWpsDNTZ599Nj744ANUVVVh8uTJkCQJc+bMwc8//4wPPvgAp512WjTbSRQ/bDblfEqKdu2g2PJ4gLFjRaGRq64Chg/XukVERETUxCLaZ6pfv3748ccfsWvXLmzcuBE//fQTfvrpJxw8eBCnnHJKtNpIFF/UU/ySk7VtC8XOs88CX3whslFPPql1a4iIiEgDIU/zKy8vx5tvvonDhw+jS5cuGDZsGDp06IAOHTrg9ddfx4gRI/DDDz+gTZs2sWgvkb45HIDbLc5zil/iKikB7r1XnJ89G2jVStv2EBERkSZCCqZ++eUXXHTRRSgtLYUkSTAYDOjTpw/efPNNXH/99VizZg2ys7Px2GOPYcKECbFqM5F+yVkpgFmpRHb33cqeUuPGad0aIiIi0khIwdSMGTNQUVGBmTNn4uyzz8Zvv/2G2bNno3fv3vjhhx9w66234rHHHkN2dnaMmkukcwymEt977wGrVnFPKSIiIgotmNqwYQMeeOABTJs2zXtdx44dMXToUNx+++34xz/+EfUGEsUNp1MUIwDEFD9jREsSSY8qK5U9pSZN4p5SREREzVxIo70jR47gggsu8LnuwgsvBABce+210WsVUTxiVirxTZ8O7N8PtG8PzJqldWuIiIhIYyEFU263G8l+g0T5ckZGRvRaRRSP1CXRGUwlnk2bgL//XZx/+mkgNVXb9hAREZHmQq7mt3PnTpjNyq+5/6hc9tNPP9W571mcAkPNhculTPFLSuI6mkRjtwO33gpIEjBmDDBwoNYtIiIiIh0IOZgaM2ZMwOtvuukm73m50p8caBElPE7xS2zz5gE//ggUFAALFmjdGiIiItKJkIKp559/PlbtIIpv6il+KSnatYOib8cOsZcUACxZAuTmatseIiIi0o2QgqnRo0fHqh1E8cvtFpX8AMBi4RS/ROJ2i+l9TicwbBhwzTVat4iIiIh0hLWbiSLFKX6Ja+lS4MsvgYwM4B//AAwGrVtEREREOsJgiihSnOKXmPbuBe67T5yfNw9o1Urb9hAREZHuMJgiioTbDTgc4rzZLE4U/yQJuP12oLoauPBCcZ6IiIjID4MponBJEnD8uHKZWanEsXIlsGYNYLUCzz0HGPlRSURERHVxhEAUrrIypfCEyQSkpWnbHoqOw4eBiRPF+ZkzgS5dtGwNERER6RiDKaJwnDihFJ4wGoG8PGYvEsVf/yoyjmecAUyerHVriIiISMc4+iMKVVUVUFMjzhsMQE4O10olirfeAl59VWQaly0Tpe6JiIiI6sFgiigUNhtQUaFczs4W62oo/p04Adx5pzh/zz3AWWdp2hwiIiLSPwZTRMGy28WAW5aZyaITiWTqVOD334HOnYEHH9S6NURERBQHGEwRBcPjEQUnJElcTksD0tO1bRNFzyefAM8+K84/9xyDZCIiIgoKgymiYFRViYAKENP6srK0bQ9FT00NcOut4vwddwAXXaRte4iIiChuMJgiaozLJYIpQBScyM7WtDkUZQ8+CPz2G9C6NTBvntatISIiojjCYIqoMeqCE+npotIbJYavvwYWLRLn//lPsQ6OiIiIKEgMpogaYrcr+0mZTFwnlUgcDuCWW8T0zRtvBC69VOsWERERUZxhMEXUkPJy5XxmppjmR4lh7lxg+3agRQslO0VEREQUAgZTRPWprhbrpQAgKYkV3hLJ9u3A7Nni/JIlQH6+tu0hIiKiuMRgiigQjweorFQucy1N4nC7xfQ+pxO44gpg5EitW0RERERxisEUUSDqUugpKSIzRYnhiSdE4YmsLOAf/+DUTSIiIgobgykif/6l0JmVShy//go88IA4P38+UFysbXuIiIgorjGYIvKnnt7HUuiJw+MRm/PabED//mKqHxEREVEEGEwRqUmSUgrdaGQp9ETy7LPA+vVAaqo4z+l9REREFCEGU0RqtbUioAKA5GQOuBPF/v3APfeI83PmAO3ba9seIiIiSggMpojUbDblPEuhJwZJAm6/XUzf7NULGD9e6xYRERFRgmAwRSTzeJQpfiYTYLVq2x6KjpdeAt5/X1RkXLaMa+CIiIgoajQPpj799FMMGzYMxcXFMBgMePPNN31uHzNmDAwGg8/p/PPP97mP3W7HhAkTkJ+fj7S0NAwfPhwHDhxowldBCUEOpABmpRLF4cPAXXeJ83/7G3DKKdq2h4iIiBKK5sFUdXU1Tj/9dDz11FP13ueSSy7BoUOHvKf333/f5/aJEyfijTfewKpVq7Bx40ZUVVXh8ssvh9vtjnXzKZHU1CjnGUwlhvHjgePHgTPOUNZMEREREUWJWesGDB06FEOHDm3wPlarFYWFhQFvKy8vx7Jly/Diiy9i4MCBAICVK1eidevWWLduHYYMGRL1NlMCcrsBh0OcN5sBi0Xb9lDkXn8deO01Ma3vX//i35SIiIiiTvNgKhjr169HQUEBsrOz0adPH8yePRsFBQUAgK1bt8LpdGLw4MHe+xcXF6Nbt27YtGlTvcGU3W6H3W73Xq6oqAAAOJ1OOJ3OGL4ahdPphMvlarLnowZUVQHy3yE5WTmvQ+w3QTh2DOY774QBgHvKFHi6ddP137SpsO9QONhvKBzsNxQOPfWbYNug+2Bq6NChuOaaa9CmTRvs3r0bM2bMQP/+/bF161ZYrVaUlJQgKSkJOTk5Pr/XsmVLlJSU1Pu4c+fOxaxZs+pcf/ToUZ8gK5ZcLhfKysoAAGaz7v8UCc147Jh3sO0xGHzXT+kM+03jsidMgOXwYTg7d8aRsWOBI0e0bpIusO9QONhvKBzsNxQOPfWbysrKoO6n+9597bXXes9369YNZ599Ntq0aYP33nsPI0aMqPf3JEmCoYE9gqZNm4ZJkyZ5L1dUVKB169bIz89HZmZmdBrfCDnizc/Ph4VTkLTjcilZC4sFaNFC2/Y0gv2mYYZ334X59dchGY0wPP88WrRqpXWTdIN9h8LBfkPhYL+hcOip31iDrOqs+2DKX1FREdq0aYNdu3YBAAoLC+FwOFBWVuaTnSotLUXv3r3rfRyr1RrwTbJYLE36xzObzU3+nOSntlZZT5OVFRdra9hv6lFWBowbBwAwTJ4McwOfAc0V+w6Fg/2GwsF+Q+HQS78J9vk1r+YXqmPHjmH//v0oKioCAPTs2RMWiwVr16713ufQoUPYvn17g8EUkZd6o97kZO3aQZGbNAk4dAjo3BkIMI2XiIiIKJo0z0xVVVXhl19+8V7evXs3vvvuO+Tm5iI3NxczZ87E1VdfjaKiIuzZswfTp09Hfn4+rrrqKgBAVlYWbrnlFkyePBl5eXnIzc3FlClT0L17d291P6J6ORximh8gNunlhq7x64MPgOXLAYMBeP55lrcnIiKimNM8mNqyZQv69evnvSyvYxo9ejSWLl2Kbdu24YUXXsCJEydQVFSEfv364ZVXXkFGRob3dxYtWgSz2YyRI0fCZrNhwIABWL58OUwcGFNj1FkpDr7jV3k58Je/iPMTJwLMShMREVET0DyY6tu3LyRJqvf2Dz/8sNHHSE5OxpIlS7BkyZJoNo2aAzmYMhg4xS+eTZkCHDwIdOwIPPKI1q0hIiKiZiLu1kwRRY3dDng84rzVChj57xCXPvoIeO45cX7ZMiA1Vdv2EBERUbPB0SM1X+r9xDjFLz6dOAHccos4P348cPHFmjaHiIiImhcGU9R8ORzK+SD3EiCdmTgROHBATO+bN0/r1hAREVEzw2CKmiePRwmmzGZO8YtHb78NrFgh1rstXw6kpWndIiIiImpmOIKk5olZqfh29Chw223i/JQpwAUXaNseIiIiapYYTFHzxGAqvo0bBxw+DJx6KvDQQ1q3hoiIiJopBlPUPKmLTyQladcOCt0rrwCvvio2WH7hBZa0JyIiIs0wmKLmx+MBnE5x3mLheql4UlIC3HmnOH///UDPntq2h4iIiJo1jiKp+eEUv/gkSWKd1PHjwJlnimCKiIiISEMMpqj54RS/+PTcc8A774hs4ooV/NsRERGR5hhMUfOjDqaYmYoPP/8s9pQCgDlzgO7dNW0OEREREcBgipobjwdwucT5pCSxRxHpm9MJ3HgjUFMD9OsHTJqkdYuIiIiIADCYouaGU/ziz0MPAZs3A9nZYnofC4YQERGRTnBUQs0Li0/El40bxbQ+AHj6aaB1a23bQ0RERKTCYIqaFzkzZTAwM6V35eXATTeJqZl/+hMwcqTWLSIiIiLywWCKmg+3W1kvZbFwvZTeTZgA7NkDtGsHLFmidWuIiIiI6mAwRc0Hp/jFj1deAV58UayPevFFIDNT6xYRERER1cFgipoPFp+ID3v2AGPHivP33w9ccIGmzSEiIiKqD4Mpaj64Xkr/nE5g1CixXur884EZM7RuEREREVG9GExR8+B2ixPA/aX0bOZM4IsvgKws4N//FmvbiIiIiHSKwRQ1D5zip3///S8wd644/+yzQNu2mjaHiIiIqDEMpqh5UAdTLD6hP0eOADfeCEgS8Je/ANdco3WLiIiIiBrFYIqaB7mSn8HAqWN6I0nAmDHAoUPAKacAixdr3SIiIiKioDCYosTncnG9lJ498QTw/vsiY/jKK0BqqtYtIiIiIgoKgylKfNxfSr+++QaYOlWcX7gQ6N5d2/YQERERhYDBFCU+dTDF4hP6UV4u1kY5ncCVVwJ33KF1i4iIiIhCwmCKEp96fymul9IHSQJuvhn47TdRte9f/+L0SyIiIoo7DKYosXF/KX1asgR4/XUR3L76KpCTo3WLiIiIiELGYIoSG6f46c/XXwNTpojz8+cD55yjbXuIiIiIwsRgihIbN+vVl7IyYORIsU7q6quBCRO0bhERERFR2BhMUWJT7y/FYEpb8n5Se/cC7dsDy5Zx2iURERHFNQZTlLjcbrHHFCDW5nDgrq2FC4G33xZB7X/+A2Rlad0iIiIioogwmKLExf2l9OPTT4H77hPnFy8GzjpL0+YQERERRQODKUpcLD6hD/v3A//3fyJLeP31wO23a90iIiIioqhgMEWJi8UntFdbKwpNHDkCnH468NxznG5JRERECYPBFCUmj0dZL8X9pbQhScCddwKbNwO5ucAbbwCpqVq3ioiIiChqGExRYuIUP+0tXQo8/zxgNAKvvAK0a6d1i4iIiIiiisEUJSZO8dPWZ58Bd90lzj/6KDBwoLbtISIiIooBBlOUmJiZ0s6BA0rBieuuAyZP1rpFRERERDHBYIoSj8cDOJ3ivMUipplR07DZgBEjgNJSoEcPFpwgIiKihMZRJiUeZqW0IUnAzTf7FpxIS9O6VUREREQxw2CKEg8369XGI48Aq1YBZjOwejXQvr3WLSIiIiKKKQZTlHiYmWp6q1cDDz4ozv/jH0Dfvpo2h4iIiKgpMJiixCJJSjBlNnO9VFP45hvgppvE+bvuAv7yF23bQ0RERNREONKkxMIpfk3r0CFg+HBReGLIEGD+fK1bRERERNRkNA+mPv30UwwbNgzFxcUwGAx48803fW6XJAkzZ85EcXExUlJS0LdvX+zYscPnPna7HRMmTEB+fj7S0tIwfPhwHDhwoAlfBekG95dqOjYbcOWVwMGDQNeuYmNes1nrVhERERE1Gc2Dqerqapx++ul46qmnAt7+2GOPYeHChXjqqaewefNmFBYWYtCgQaisrPTeZ+LEiXjjjTewatUqbNy4EVVVVbj88svhdrub6mWQXnC9VNPweIAxY4CvvxaV+955B8jK0rpVRERERE1K88PIQ4cOxdChQwPeJkkSFi9ejPvvvx8jRowAAKxYsQItW7bEyy+/jLFjx6K8vBzLli3Diy++iIEDBwIAVq5cidatW2PdunUYMmRIk70W0pjHowRTFgtgMmnbnkQ2bRrw6qvifX7tNaBjR61bRERERNTkNA+mGrJ7926UlJRg8ODB3uusViv69OmDTZs2YezYsdi6dSucTqfPfYqLi9GtWzds2rSp3mDKbrfDrpoSVlFRAQBwOp1wyhu+xpjT6YTL5Wqy50t4NTXKZr3Jycr5BKN1vzE+8wxMjz0GAHA9/TSkCy9M2Pc60Wjddyg+sd9QONhvKBx66jfBtkHXwVRJSQkAoGXLlj7Xt2zZEnv37vXeJykpCTk5OXXuI/9+IHPnzsWsWbPqXH/06FGfICuWXC4XysrKAABmrjWJmKGsDIY//nYeSQJqazVuUWxo2W+sH3+M3L/+FQBQMWUKqoYMAY4cadI2UPj4mUPhYL+hcLDfUDj01G/US4oaEhe922Aw+FyWJKnOdf4au8+0adMwadIk7+WKigq0bt0a+fn5yMzMjKzBQZIj3vz8fFgsliZ5zoQlSYDLBaSni3LohYVatyhmNOs3334L8x13wODxwDN6NFJmz0ZKI/+HpC/8zKFwsN9QONhvKBx66jfWIKtC6zqYKvxjQFxSUoKioiLv9aWlpd5sVWFhIRwOB8rKynyyU6Wlpejdu3e9j221WgO+SRaLpUn/eGazucmfMyHV1iqV5FJTxVqeBNbk/WbfPuCKK4DqamDgQBiffRbGBH+PExU/cygc7DcUDvYbCode+k2wz695Nb+GtGvXDoWFhVi7dq33OofDgQ0bNngDpZ49e8Jisfjc59ChQ9i+fXuDwRQlGPXUzORk7dqRiMrKgEsvBUpKgO7dRcEJfjESERERaZ+Zqqqqwi+//OK9vHv3bnz33XfIzc3FySefjIkTJ2LOnDno1KkTOnXqhDlz5iA1NRWjRo0CAGRlZeGWW27B5MmTkZeXh9zcXEyZMgXdu3f3VvejZkBeH2UwcLPeaKqqEoHUjh1AURHw3nssgU5ERET0B82DqS1btqBfv37ey/I6ptGjR2P58uWYOnUqbDYb7rzzTpSVleG8887DRx99hIyMDO/vLFq0CGazGSNHjoTNZsOAAQOwfPlymFgau3lwOgF5T7GkJBFQUeTsdmDECODLL4GcHOCjj4DWrbVuFREREZFuGCRJkrRuhB5UVFQgKysL5eXlTVqA4siRI2jRooXm80LjWmWlOAEia5KWpm17YqxJ+o3LBVx7LfD66+L9/Phj4LzzYvNc1GT4mUPhYL+hcLDfUDj01G+CjQ10vWaKKCjqEuhcLxU5jwe47TYRSCUlAW+9xUCKiIiIKAAGUxTf3G5lw1iLBeDUzshIEjBlCvD886LE/KpVwIABWreKiIiISJcYTFF8YxW/6Hr4YWDRInH+X/8CrrpK2/YQERER6RiDKYpv6il+rOIXmUceAf72N3F+8WJg9GhNm0NERESkdwymKH5JkpKZMhrF+h4Kz+zZwIwZ4vzcucBdd2nbHiIiIqI4wGCK4pfdLgIqgFP8IjF7NvDAA+L83LnAffdp2x4iIiKiOMFgiuIX10tFbs4cJZCaM4eBFBEREVEIGExR/JLXSxkMXC8VjjlzgPvvF+dnzwamTdO2PURERERxhsEUxSenU5RFB0QgZTBo2554IknAQw/5BlLTp2vbJiIiIqI4ZNa6AURhYRW/8EgSMHmyUv78kUcYSBERERGFicEUxSebTTnP9VLBcbuBsWOBZcvE5cWLWbWPiIiIKAIMpij+uFziBIhy6CaTtu2JBw4HcOONwH/+I8rIL1sGjBmjdauIiIiI4hqDKYo/6il+zEo1rqYGuPpqYM0awGIBVq0CRozQulVEREREcY/BFMUfBlPBKysDhg8HNm4EUlOBN94ABg/WulVERERECYHBFMUXt1tMWQMAs1mcKLD9+4GhQ4EdO4CsLOC994ALLtC6VUREREQJgyNRii/qrFRKinbt0Lvt24FLLgEOHgSKi4EPPgB69NC6VUREREQJhftMUXzhFL/GbdgAXHihCKROOQX44gsGUkREREQxwGCK4ofHA9jt4rzJJIopkK9XXxVrosrLxZS+jRuBk0/WulVERERECYnBFMUPOZACOMXPnySJfaOuu06sKRsxAli7FsjN1bplRERERAmLwRTFD27UG5jLBUyYANx9twiqxo0TGSoGnEREREQxxQIUFB8kSclMGY1is14CKipENuqDDwCDAXj0UWDKFHGeiIiIiGKKwRTFB7tdBFQAs1KyffuAq64Ctm0TWaiXXhKXiYiIiKhJcJofxQf1FD9OX4Pl++9hvvBCEUgVFooKfgykiIiIiJoUM1Okf+opfgZDs5/iZ3jjDeSNHg1DbS3QvTvw7rus2EdERESkAWamSP8cDlEWHRBT/JrreiBJAh5+GOZrr4WxthaeIUNY+pyIiIhIQ8xMkf5xo16gpga4+WbglVcAAFW33ALrkiUwcsojERERkWYYTJH+ycGUwdA8g6mDB4ErrgC2bgXMZriWLEHF8OFoYea/LxEREZGWOBojfautBdxucd5qbX5T/L7+GrjySuDQISAvD1i9GlLv3sCRI1q3jIiIiKjZ45op0reqKuV8Wpp27dDCiy8CffqIQOq004DNm8VlIiIiItIFBlOkXw6HOAGA2SwyU82B0wlMnAj86U8iM3f55cCmTUC7dlq3jIiIiIhUGEyRflVXK+fT07VrR1M6cgQYPBh44glxecYM4K23gMxMbdtFRERERHVwzRTpk9utbNRrNDaPjXq/+UZsvLtvnwgeX3iBG/ESERER6RgzU6RP/mulEr3wxMqVwAUXiECqUyfgq68YSBERERHpHIMp0h+PR+yrBIggKpELT9jtwLhxwE03ifVRl14qKvideqrWLSMiIiKiRjCYIv2pqQEkSZxPTRXT/BLR/v2iOt8//iEuz5gBvP02kJ2tabOIiIiIKDhcM0X6Ikm+hScSNSu1di1w/fXAsWNATo6Y5nfppVq3ioiIiIhCkKCH/CluqTfpTU4WJdETiccDzJ4NDBkiAqmzzgK2bmUgRURERBSHEmykSnFPXXgi0cqhl5aKvaM+/FBc/stfgCefFEEjEREREcUdBlOkH3a72LAWACwWIClJ2/ZE08cfAzfeCJSUiODp738Hbr5Z61YRERERUQQ4zY/0IxGzUi4X8MADwKBBIpA67TRg82YGUkREREQJgJkp0ge7XZwAwGRKjE169+0DRo0CPv9cXL7tNmDRIlGhkIiIiIjiHjNTpA/l5cr5zEzt2hEtq1YBp58uAqnMTHH56acZSBERERElEGamSHs1NWI6HCDWScVzVurYMeDOO4FXXxWXzzlHBFLt22vbLiIiIiKKOmamSFuSBFRUKJfjOSv1/vtAt24ikDKZgJkzRWaKgRQRERFRQtJ9MDVz5kwYDAafU2Fhofd2SZIwc+ZMFBcXIyUlBX379sWOHTs0bDGFpKpK7L0EiCp38VjBr7JSrIe67DJRZKJrV+DLL4G//U1UJSQiIiKihKT7YAoATjvtNBw6dMh72rZtm/e2xx57DAsXLsRTTz2FzZs3o7CwEIMGDUJlZaWGLaaguN2+FfziMSv1ySdibdSzz4rLd98NfPMNcPbZ2raLiIiIiGIuLtZMmc1mn2yUTJIkLF68GPfffz9GjBgBAFixYgVatmyJl19+GWPHjm3qplIoKivFND8ASEsDzHHRHYWqKuDee4F//ENcPvlkYPlyoF8/TZtFRERERE0nLkavu3btQnFxMaxWK8477zzMmTMH7du3x+7du1FSUoLBgwd772u1WtGnTx9s2rSpwWDKbrfDLpfiBlDxx7odp9MJp7xxbIw5nU64XK4mez5dcbmUCn4Gg5jiFyfvg2HDBphuuw2G3bsBAO6//AWeefOAjIwmeQ3Nut9QRNh3KBzsNxQO9hsKh576TbBt0H0wdd555+GFF15A586dcfjwYTzyyCPo3bs3duzYgZKSEgBAy5YtfX6nZcuW2Lt3b4OPO3fuXMyaNavO9UePHvUJsmLJ5XKhrKwMgMi+NSeG48dhcDgAAFJGBqRjxzRuUeMM1dXInDMHacuXAwBcJ52EE/Pnw3HxxUBtrTg1gebcbygy7DsUDvYbCgf7DYVDT/0m2CVDuu/dQ4cO9Z7v3r07evXqhQ4dOmDFihU4//zzAQAGg8HndyRJqnOdv2nTpmHSpEneyxUVFWjdujXy8/OR2URrd+SINz8/H5bmVKigtlbJ4JhMQEGByE7pmGHtWpjuvBOGP4J09623Qpo3D1karPNqtv2GIsa+Q+Fgv6FwsN9QOPTUb6xWa1D3030w5S8tLQ3du3fHrl27cOWVVwIASkpKUFRU5L1PaWlpnWyVP6vVGvBNslgsTfrHM5vNTf6cmnK5xHoj+fXm5Oi7gt/x48CkScCKFeLyyScDy5bBNHAgTBo2q9n1G4oa9h0KB/sNhYP9hsKhl34T7PPHRTU/Nbvdjh9//BFFRUVo164dCgsLsXbtWu/tDocDGzZsQO/evTVsJQXk8YhNbeWiEykp+t2gV5KA114DTjlFBFIGA/DXvwI7dgADB2rdOiIiIiLSAd1npqZMmYJhw4bh5JNPRmlpKR555BFUVFRg9OjRMBgMmDhxIubMmYNOnTqhU6dOmDNnDlJTUzFq1Citm05qkgSUlYly6IDITGVna9qkeh08CEyYALzxhrjctSuwbBnAAJ2IiIiIVHQfTB04cADXX389jh49ihYtWuD888/Hl19+iTZt2gAApk6dCpvNhjvvvBNlZWU477zz8NFHHyEjI0PjlpOPigpALuxhNAK5ufpbJ+V2i1Ln998vyrabzcC0aeJykPNmiYiIiKj50H0wtWrVqgZvNxgMmDlzJmbOnNk0DaLQ1dQA1dXivMEgAimTliuOAvjmG2DsWGDLFnH5vPOAZ54BevTQtl1EREREpFtxt2aK4ozDAZw4oVzOytJXwYmqKlFg4pxzRCCVlQUsXQps2sRAioiIiIgapPvMFMUxt1tUw5OlpQGpqdq1x9+bb4q1UQcOiMvXXgssWgSoKkMSEREREdWHwRTFhiSJQMrjEZetVpH10YN9+0QQ9fbb4nK7dmKt1CWXaNsuIiIiIoornOZHsXHihLIxr9ks9pPSmtMJzJ8vyp2//bZSYGL7dgZSRERERBQyZqYo+qqqAJtNnJcLThg1jts//xy4807gf/8Tly+6SKyNOu00bdtFRERERHGLmSmKrtpaUQZdlpMjMkBa2bNHrIW68EIRSOXmij2j1q9nIEVEREREEWFmiqLH5RIb88oyMoDkZG3aUlkJzJ0LLFwo9rcyGIBbbgHmzAFatNCmTURERESUUBhMUXR4PKLghCSJy8nJIphqai4XsHw58MADwOHD4rr+/UVQdfrpTd8eIiIiIkpYDKYocpIkMlIul7isRcEJux144QVg3jzgt9/EdR07AgsWAMOGicwUEREREVEUMZiiyMgZKYdDXDYagby8pgteamqA554DHn9c2S8qPx+YPh0YN05fGwQTERERUUJhMEXh83iAY8eUEuhGoyjwYDLF/rmPHQOefVZssltaKq4rLgbuuQf4y1/EBsFERERERDHEYIrC43aLgEae2idnpCyW2D7v998DS5YAL70kKgcCQNu2wH33AWPGiM2BiYiIiIiaAIMpCp3bDRw9Kn4CIhOVlxe7EuhOJ/DWWyKI+vRT5fqzzgLuugu4/vrYB3FERERERH4YTFFo7HbgxAklkDKbRSAVi6l927eLynwrVyqV+Uwm4P/+D/jrX4FevVhYgoiIiIg0w2CKguN2A+XlytQ6IDaB1LFjwL//LYKorVuV6wsKgNtuA26/HTjppOg9HxERERFRmBhMUcMkCaiqEid5DylAVMnLzRVrpSL122/Au+8C77wDbNigFLQwm0VZ8zFjgKFDOZWPiIiIiHSFwRTVr7YWqKhQikwAInjKzARSU8N/XLsd+Oor4L33RBD1ww++t595pgigrr8eaNEi/OchIiIiIoohBlPkS5LE3k3V1b5BFCDKjWdkhJ6NcrmAb74B/vtfcdq4EbDZlNtNJuCii0QW6vLLgc6dI38dREREREQxxmCKBI9HBFDV1eK8WlISkJUV/DS72lpgyxYRNH32mfhZUeF7n4ICYOBAEUANGQLk5ETndRARERERNREGU82ZxyMCn9paMfVOvSYKEHs2paUByckNP8avvwLffisKRnz+ObB5M+Bw+N4vOxvo2xfo31+cTj2VlfiIiIiIKK4xmGpuXC4lgPIPeGQpKUB6et1MVHm5WN+0Y4fYPPfbb8XPqqq6j9GyJXDhheJ00UXAGWfEpnw6EREREZFGGEw1B263WKNksymV8vwZjaKohMUCHDggsku//Qbs2iWCpx07xPWBJCcD3buLgKlXLxE8dejAzBMRERERJTQGU4lIkkQGym73DaBqaoDffwcOHQJKS4GjR8XpyBGxKe7u3SJg8p/up1ZcDJx2mgiezjxTnLp0EWXMiYiIiIiaEY6A9cbjAR5+WBR96NoVOOUUoH17cVlNksR93W4ROLlcwPHjIiD67Tdg3z5g/37g4EERQB08CJSVBdeGlBTxnO3aiQzTqaeKAOrUU1kogoiIiIjoDwym9MbpBJ58UgRGMqtVBDadOolAR17zJBeOqK4OPljKyABatQKKiuqe2rYVQVRBAafoERERERE1gsGU3rhcwKhRYq3Sr78Ce/aIgOmnn8SpMTk5QJs2IjCSg6P27YGTTxanrKwYvwAiIiIiouaBwZTepKUBS5aIKXxOp1jz9OuvIpD65RdxXUqK7yk9XQRQHTtyGh4RERERURNhMKVXRqOY3me1Aj17ipPHI6bfcQoeEREREZHmGEzFE6NR6xYQEREREdEfODonIiIiIiIKA4MpIiIiIiKiMDCYIiIiIiIiCgODKSIiIiIiojAwmCIiIiIiIgoDgykiIiIiIqIwMJgiIiL6//buNCaqs30D+DVsA+IwCgjjiCwmtqijolD3ikgVFdDW2tQd7QdrWxQkrVq1kVh9UWsMaotttbGNuKUBjbWNCu5WcEMUNVatgiuCCwOuoHP/P7yvJz2C1v8pMmivXzIf5jk359wzXiHczuGBiIhIAw5TREREREREGnCYIiIiIiIi0oDDFBERERERkQYcpoiIiIiIiDTgMEVERERERKQBhykiIiIiIiINOEwRERERERFpwGGKiIiIiIhIAw5TREREREREGnCYIiIiIiIi0sDJ3g3UFyICACgvL6+za1ZVVaGiogJ6vR7Ozs51dl16uTE3pBWzQ1owN6QFc0Na1KfcPJ4JHs8IT8Nh6n8qKioAAM2bN7dzJ0REREREVB9UVFTAaDQ+9bhO/m7c+pew2Wy4cuUKDAYDdDpdnVyzvLwczZs3x8WLF+Hh4VEn16SXH3NDWjE7pAVzQ1owN6RFfcqNiKCiogJmsxkODk//zSh+MvU/Dg4O8PPzs8u1PTw87B4YevkwN6QVs0NaMDekBXNDWtSX3DzrE6nHuAEFERERERGRBhymiIiIiIiINOAwZUd6vR4zZ86EXq+3dyv0EmFuSCtmh7RgbkgL5oa0eBlzww0oiIiIiIiINOAnU0RERERERBpwmCIiIiIiItKAwxQREREREZEGHKaIiIiIiIg04DBlR2lpaQgKCoKrqytCQ0OxZ88ee7dEL0BKSgreeOMNGAwG+Pj44O2338Yff/yhqhERJCcnw2w2w83NDb169cKJEydUNQ8ePMCECRPg7e0Nd3d3DBw4EJcuXVLV3Lp1C6NGjYLRaITRaMSoUaNQVlamqrlw4QJiY2Ph7u4Ob29vTJw4EZWVlS/ktVPtSUlJgU6nQ2JiorLG3FBNLl++jJEjR8LLywsNGjRASEgIDh8+rBxnbuhJDx8+xIwZMxAUFAQ3Nze0aNECs2bNgs1mU2qYGwKA3bt3IzY2FmazGTqdDhs2bFAdr285KSgoQHh4ONzc3NCsWTPMmjULtb73npBdrF27VpydnWXZsmVy8uRJSUhIEHd3dykqKrJ3a1TLoqKiZMWKFXL8+HHJz8+X6Oho8ff3l9u3bys1c+fOFYPBIBkZGVJQUCDvv/++NG3aVMrLy5Wa8ePHS7NmzSQrK0vy8vIkIiJC2rdvLw8fPlRq+vXrJxaLRfbt2yf79u0Ti8UiMTExyvGHDx+KxWKRiIgIycvLk6ysLDGbzRIfH183bwZpcuDAAQkMDJR27dpJQkKCss7c0JNu3rwpAQEBMmbMGNm/f7+cP39esrOz5ezZs0oNc0NPmj17tnh5ecmmTZvk/Pnz8vPPP0vDhg0lNTVVqWFuSETkt99+k+nTp0tGRoYAkPXr16uO16ecWK1W8fX1laFDh0pBQYFkZGSIwWCQBQsW1Op7wmHKTjp16iTjx49XrQUHB8vUqVPt1BHVlZKSEgEgu3btEhERm80mJpNJ5s6dq9Tcv39fjEajfPvttyIiUlZWJs7OzrJ27Vql5vLly+Lg4CCbN28WEZGTJ08KAMnNzVVqcnJyBICcOnVKRP77TdDBwUEuX76s1KxZs0b0er1YrdYX96JJs4qKCmnZsqVkZWVJeHi4MkwxN1STKVOmSI8ePZ56nLmhmkRHR8sHH3ygWhs8eLCMHDlSRJgbqtmTw1R9y0laWpoYjUa5f/++UpOSkiJms1lsNlutvQ+8zc8OKisrcfjwYfTt21e13rdvX+zbt89OXVFdsVqtAABPT08AwPnz51FcXKzKg16vR3h4uJKHw4cPo6qqSlVjNpthsViUmpycHBiNRnTu3Fmp6dKlC4xGo6rGYrHAbDYrNVFRUXjw4IHqNiCqPz755BNER0fjrbfeUq0zN1STjRs3IiwsDO+99x58fHzQoUMHLFu2TDnO3FBNevTogW3btuH06dMAgKNHj2Lv3r0YMGAAAOaGnk99y0lOTg7Cw8NVfwA4KioKV65cQWFhYa29bqdaOxM9t+vXr+PRo0fw9fVVrfv6+qK4uNhOXVFdEBEkJSWhR48esFgsAKD8m9eUh6KiIqXGxcUFjRs3rlbz+OuLi4vh4+NT7Zo+Pj6qmiev07hxY7i4uDB79dDatWuRl5eHgwcPVjvG3FBNzp07h6VLlyIpKQnTpk3DgQMHMHHiROj1eowePZq5oRpNmTIFVqsVwcHBcHR0xKNHjzBnzhwMGzYMAL/f0POpbzkpLi5GYGBgtes8PhYUFKTlZVbDYcqOdDqd6rmIVFujV0t8fDyOHTuGvXv3VjumJQ9P1tRUr6WG7O/ixYtISEjA1q1b4erq+tQ65ob+ymazISwsDP/5z38AAB06dMCJEyewdOlSjB49Wqljbuiv1q1bh/T0dKxevRpt2rRBfn4+EhMTYTabERcXp9QxN/Q86lNOaurlaV+rFW/zswNvb284OjpW+x+WkpKSalM2vTomTJiAjRs3YseOHfDz81PWTSYTADwzDyaTCZWVlbh169Yza65du1btuqWlpaqaJ69z69YtVFVVMXv1zOHDh1FSUoLQ0FA4OTnByckJu3btwuLFi+Hk5KT637W/Ym7+3Zo2bYrWrVur1lq1aoULFy4A4Pcbqtlnn32GqVOnYujQoWjbti1GjRqFSZMmISUlBQBzQ8+nvuWkppqSkhIA1T89+yc4TNmBi4sLQkNDkZWVpVrPyspCt27d7NQVvSgigvj4eGRmZmL79u3VPlYOCgqCyWRS5aGyshK7du1S8hAaGgpnZ2dVzdWrV3H8+HGlpmvXrrBarThw4IBSs3//flitVlXN8ePHcfXqVaVm69at0Ov1CA0Nrf0XT5pFRkaioKAA+fn5yiMsLAwjRoxAfn4+WrRowdxQNd27d6/2pxdOnz6NgIAAAPx+QzW7e/cuHBzUPxI6OjoqW6MzN/Q86ltOunbtit27d6u2S9+6dSvMZnO12//+kVrbyoL+Xx5vjf7DDz/IyZMnJTExUdzd3aWwsNDerVEt++ijj8RoNMrOnTvl6tWryuPu3btKzdy5c8VoNEpmZqYUFBTIsGHDatxK1M/PT7KzsyUvL0969+5d41ai7dq1k5ycHMnJyZG2bdvWuJVoZGSk5OXlSXZ2tvj5+XHL2ZfEX3fzE2FuqLoDBw6Ik5OTzJkzR86cOSOrVq2SBg0aSHp6ulLD3NCT4uLipFmzZsrW6JmZmeLt7S2TJ09WapgbEvnvDrNHjhyRI0eOCABZuHChHDlyRPnTPvUpJ2VlZeLr6yvDhg2TgoICyczMFA8PD26N/ir55ptvJCAgQFxcXKRjx47KVtn0agFQ42PFihVKjc1mk5kzZ4rJZBK9Xi89e/aUgoIC1Xnu3bsn8fHx4unpKW5ubhITEyMXLlxQ1dy4cUNGjBghBoNBDAaDjBgxQm7duqWqKSoqkujoaHFzcxNPT0+Jj49XbRtK9deTwxRzQzX55ZdfxGKxiF6vl+DgYPn+++9Vx5kbelJ5ebkkJCSIv7+/uLq6SosWLWT69Ony4MEDpYa5IRGRHTt21PgzTVxcnIjUv5wcO3ZM3nzzTdHr9WIymSQ5OblWt0UXEdGJ1PafASYiIiIiInr18XemiIiIiIiINOAwRUREREREpAGHKSIiIiIiIg04TBEREREREWnAYYqIiIiIiEgDDlNEREREREQacJgiIiIiIiLSgMMUERERERGRBhymiIjohdPpdM/12LlzJ8aMGYPAwEB7t/xUq1evRmpqqr3bICKiekAnImLvJoiI6NWWm5urev7ll19ix44d2L59u2q9devWKC0tRXl5OTp06FCXLT63mJgYHD9+HIWFhfZuhYiI7MzJ3g0QEdGrr0uXLqrnTZo0gYODQ7V1APDw8KirtoiIiP4R3uZHRET1Sk23+el0OsTHx2PFihV4/fXX4ebmhrCwMOTm5kJE8NVXXyEoKAgNGzZE7969cfbs2Wrnzc7ORmRkJDw8PNCgQQN0794d27ZtU9WUlpZi3LhxaN68OfR6PZo0aYLu3bsjOzsbANCrVy/8+uuvKCoqUt2e+FhlZSVmz56N4OBg5evHjh2L0tJS1XUCAwMRExOD9evXo127dnB1dUWLFi2wePFiVZ3NZsPs2bOV19yoUSO0a9cOixYt+idvMRER1RJ+MkVERC+FTZs24ciRI5g7dy50Oh2mTJmC6OhoxMXF4dy5c/j6669htVqRlJSEd999F/n5+cqgk56ejtGjR2PQoEH46aef4OzsjO+++w5RUVHYsmULIiMjAQCjRo1CXl4e5syZg9deew1lZWXIy8vDjRs3AABpaWkYN24c/vzzT6xfv17Vn81mw6BBg7Bnzx5MnjwZ3bp1Q1FREWbOnIlevXrh0KFDcHNzU+rz8/ORmJiI5ORkmEwmrFq1CgkJCaisrMSnn34KAJg/fz6Sk5MxY8YM9OzZE1VVVTh16hTKysrq4B0nIqK/JURERHUsLi5O3N3dn3osICBAtQZATCaT3L59W1nbsGGDAJCQkBCx2WzKempqqgCQY8eOiYjInTt3xNPTU2JjY1XnfPTokbRv3146deqkrDVs2FASExOf2Xt0dHS1/kRE1qxZIwAkIyNDtX7w4EEBIGlpacpaQECA6HQ6yc/PV9X26dNHPDw85M6dOyIiEhMTIyEhIc/sh4iI7Ie3+RER0UshIiIC7u7uyvNWrVoBAPr376+61e7xelFREQBg3759uHnzJuLi4vDw4UPlYbPZ0K9fPxw8eBB37twBAHTq1Ak//vgjZs+ejdzcXFRVVT13f5s2bUKjRo0QGxuruk5ISAhMJhN27typqm/Tpg3at2+vWhs+fDjKy8uRl5en9HP06FF8/PHH2LJlC8rLy5+7HyIievE4TBER0UvB09NT9dzFxeWZ6/fv3wcAXLt2DQAwZMgQODs7qx7z5s2DiODmzZsAgHXr1iEuLg7Lly9H165d4enpidGjR6O4uPhv+7t27RrKysrg4uJS7TrFxcW4fv26qt5kMlU7x+O1x7cVfv7551iwYAFyc3PRv39/eHl5ITIyEocOHfrbfoiI6MXj70wREdErzdvbGwCwZMmSGncPBABfX1+lNjU1Fampqbhw4QI2btyIqVOnoqSkBJs3b/7b63h5eT21zmAwqJ7XNKA9XvPy8gIAODk5ISkpCUlJSSgrK0N2djamTZuGqKgoXLx4EQ0aNHhmT0RE9GJxmCIiolda9+7d0ahRI5w8eRLx8fHP/XX+/v6Ij4/Htm3b8Pvvvyvrer0e9+7dq1YfExODtWvX4tGjR+jcufPfnv/EiRM4evSo6la/1atXw2AwoGPHjtXqGzVqhCFDhuDy5ctITExEYWEhWrdu/dyvh4iIah+HKSIieqU1bNgQS5YsQVxcHG7evIkhQ4bAx8cHpaWlOHr0KEpLS7F06VJYrVZERERg+PDhCA4OhsFgwMGDB7F582YMHjxYOV/btm2RmZmJpUuXIjQ0FA4ODggLC8PQoUOxatUqDBgwAAkJCejUqROcnZ1x6dIl7NixA4MGDcI777yjnMdsNmPgwIFITk5G06ZNkZ6ejqysLMybN0/5xCk2NhYWiwVhYWFo0qQJioqKkJqaioCAALRs2bLO30siIlLjMEVERK+8kSNHwt/fH/Pnz8eHH36IiooK+Pj4ICQkBGPGjAEAuLq6onPnzli5ciUKCwtRVVUFf39/TJkyBZMnT1bOlZCQgBMnTmDatGmwWq0QEYgIHB0dsXHjRixatAgrV65ESkoKnJyc4Ofnh/DwcLRt21bVU0hICMaOHYuZM2fizJkzMJvNWLhwISZNmqTUREREICMjA8uXL0d5eTlMJhP69OmDL774As7OznXy3hER0dPpRETs3QQREdG/SWBgICwWCzZt2mTvVoiI6B/gbn5EREREREQacJgiIiIiIiLSgLf5ERERERERacBPpoiIiIiIiDTgMEVERERERKQBhykiIiIiIiINOEwRERERERFpwGGKiIiIiIhIAw5TREREREREGnCYIiIiIiIi0oDDFBERERERkQb/B62aFyW8XidOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "# env_name = 'LunarLander-v2'\n",
    "# env_name = 'BipedalWalker-v2'\n",
    "# env_name = 'RoboschoolWalker2d-v1'\n",
    "\n",
    "\n",
    "fig_num = 0     #### change this to prevent overwriting figures in same env_name folder\n",
    "\n",
    "plot_avg = True    # plot average of all runs; else plot all runs separately\n",
    "\n",
    "fig_width = 10\n",
    "fig_height = 6\n",
    "\n",
    "\n",
    "# smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
    "window_len_smooth = 50\n",
    "min_window_len_smooth = 1\n",
    "linewidth_smooth = 1.5\n",
    "alpha_smooth = 1\n",
    "\n",
    "window_len_var = 5\n",
    "min_window_len_var = 1\n",
    "linewidth_var = 2\n",
    "alpha_var = 0.1\n",
    "\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'olive', 'brown', 'magenta', 'cyan', 'crimson','gray', 'black']\n",
    "\n",
    "\n",
    "# make directory for saving figures\n",
    "figures_dir = \"PPO_figs\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "\n",
    "# make environment directory for saving figures\n",
    "figures_dir = figures_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "\n",
    "\n",
    "fig_save_path = figures_dir + '/PPO_' + env_name + '_fig_' + str(fig_num) + '.png'\n",
    "\n",
    "\n",
    "# get number of log files in directory\n",
    "log_dir = \"PPO_logs\" + '/' + env_name + '/'\n",
    "\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "num_runs = len(current_num_files)\n",
    "\n",
    "\n",
    "all_runs = []\n",
    "\n",
    "for run_num in range(num_runs):\n",
    "\n",
    "    log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "    print(\"loading data from : \" + log_f_name)\n",
    "    data = pd.read_csv(log_f_name)\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"data shape : \", data.shape)\n",
    "    \n",
    "    all_runs.append(data)\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "if plot_avg:\n",
    "    # average all runs\n",
    "    df_concat = pd.concat(all_runs)\n",
    "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
    "    data_avg = df_concat_groupby.mean()\n",
    "\n",
    "    # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
    "    data_avg['reward_smooth'] = data_avg['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
    "    data_avg['reward_var'] = data_avg['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
    "\n",
    "    data_avg.plot(kind='line', x='timestep' , y='reward_smooth',ax=ax,color=colors[0],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
    "    data_avg.plot(kind='line', x='timestep' , y='reward_var',ax=ax,color=colors[0],  linewidth=linewidth_var, alpha=alpha_var)\n",
    "\n",
    "    # keep only reward_smooth in the legend and rename it\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend([handles[0]], [\"reward_avg_\" + str(len(all_runs)) + \"_runs\"], loc=2)\n",
    "\n",
    "\n",
    "else:\n",
    "    for i, run in enumerate(all_runs):\n",
    "        # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
    "        run['reward_smooth_' + str(i)] = run['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
    "        run['reward_var_' + str(i)] = run['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
    "        \n",
    "        # plot the lines\n",
    "        run.plot(kind='line', x='timestep' , y='reward_smooth_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
    "        run.plot(kind='line', x='timestep' , y='reward_var_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_var, alpha=alpha_var)\n",
    "\n",
    "    # keep alternate elements (reward_smooth_i) in the legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = []\n",
    "    new_labels = []\n",
    "    for i in range(len(handles)):\n",
    "        if(i%2 == 0):\n",
    "            new_handles.append(handles[i])\n",
    "            new_labels.append(labels[i])\n",
    "    ax.legend(new_handles, new_labels, loc=2)\n",
    "\n",
    "\n",
    "\n",
    "# ax.set_yticks(np.arange(0, 1800, 200))\n",
    "# ax.set_xticks(np.arange(0, int(4e6), int(5e5)))\n",
    "\n",
    "\n",
    "ax.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\", fontsize=12)\n",
    "ax.set_ylabel(\"Rewards\", fontsize=12)\n",
    "\n",
    "plt.title(env_name, fontsize=14)\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(fig_width, fig_height)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "plt.savefig(fig_save_path)\n",
    "print(\"figure saved at : \", fig_save_path)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaWPRW9EGxgH"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "################################ End of Part IV ################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8uG43MtHNGC"
   },
   "source": [
    "################################################################################\n",
    "> # **Part - V**\n",
    "\n",
    "*   install virtual display libraries for rendering on colab / remote server ^\n",
    "*   load preTrained networks and save images for gif\n",
    "*   generate and save gif from previously saved images\n",
    "\n",
    "*   ^ If running locally; do not install xvbf and pyvirtualdisplay. Just comment out the virtual display code and render it normally. \n",
    "*   ^ You will still require to use ipythondisplay, if you want to render it in the Jupyter Notebook.\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VL3tpKf3HLAq"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#### to render on colab / server / headless machine install virtual display libraries\n",
    "\n",
    "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5Rx_IFKHK-D"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############################# save images for gif ##############################\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "One frame corresponding to each timestep is saved in a folder :\n",
    "\n",
    "PPO_gif_images/env_name/000001.jpg\n",
    "PPO_gif_images/env_name/000002.jpg\n",
    "PPO_gif_images/env_name/000003.jpg\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "\n",
    "if this section is run multiple times or for multiple episodes for the same env_name; \n",
    "then the saved images will be overwritten.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### beginning of virtual display code section\n",
    "\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "#### end of virtual display code section\n",
    "\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "################## hyperparameters ##################\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "has_continuous_action_space = False\n",
    "max_ep_len = 400\n",
    "action_std = None\n",
    "\n",
    "\n",
    "# env_name = \"LunarLander-v2\"\n",
    "# has_continuous_action_space = False\n",
    "# max_ep_len = 300\n",
    "# action_std = None\n",
    "\n",
    "# env_name = \"BipedalWalker-v2\"\n",
    "# has_continuous_action_space = True\n",
    "# max_ep_len = 1500           # max timesteps in one episode\n",
    "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
    "\n",
    "# env_name = \"RoboschoolWalker2d-v1\"\n",
    "# has_continuous_action_space = True\n",
    "# max_ep_len = 1000           # max timesteps in one episode\n",
    "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
    "\n",
    "\n",
    "total_test_episodes = 1     # save gif for only one episode\n",
    "\n",
    "render_ipython = False      # plot the images using matplotlib and ipythondisplay before saving (slow)\n",
    "\n",
    "K_epochs = 80               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003         # learning rate for actor\n",
    "lr_critic = 0.001         # learning rate for critic\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "# make directory for saving gif images\n",
    "gif_images_dir = \"PPO_gif_images\" + '/'\n",
    "if not os.path.exists(gif_images_dir):\n",
    "    os.makedirs(gif_images_dir)\n",
    "\n",
    "# make environment directory for saving gif images\n",
    "gif_images_dir = gif_images_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(gif_images_dir):\n",
    "    os.makedirs(gif_images_dir)\n",
    "\n",
    "# make directory for gif\n",
    "gif_dir = \"PPO_gifs\" + '/'\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "\n",
    "# make environment directory for gif\n",
    "gif_dir = gif_dir + '/' + env_name  + '/'\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "\n",
    "\n",
    "\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# preTrained weights directory\n",
    "\n",
    "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
    "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
    "\n",
    "\n",
    "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"loading network from : \" + checkpoint_path)\n",
    "\n",
    "ppo_agent.load(checkpoint_path)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "test_running_reward = 0\n",
    "\n",
    "for ep in range(1, total_test_episodes+1):\n",
    "    \n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "\n",
    "\n",
    "        #### beginning of ipythondisplay code section 1\n",
    "\n",
    "        if render_ipython:\n",
    "            plt.imshow(img)\n",
    "            ipythondisplay.clear_output(wait=True)\n",
    "            ipythondisplay.display(plt.gcf())\n",
    "\n",
    "        #### end of ipythondisplay code section 1\n",
    "\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(gif_images_dir + '/' + str(t).zfill(6) + '.jpg')\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # clear buffer    \n",
    "    ppo_agent.buffer.clear()\n",
    "    \n",
    "    test_running_reward +=  ep_reward\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
    "    ep_reward = 0\n",
    "\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "#### beginning of ipythondisplay code section 2\n",
    "\n",
    "if render_ipython:\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "\n",
    "#### end of ipythondisplay code section 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "print(\"total number of frames / timesteps / images saved : \", t)\n",
    "\n",
    "avg_test_reward = test_running_reward / total_test_episodes\n",
    "avg_test_reward = round(avg_test_reward, 2)\n",
    "print(\"average test reward : \" + str(avg_test_reward))\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoVshl_ZHK7s"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "######################## generate gif from saved images ########################\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "# env_name = 'LunarLander-v2'\n",
    "# env_name = 'BipedalWalker-v2'\n",
    "# env_name = 'RoboschoolWalker2d-v1'\n",
    "\n",
    "\n",
    "gif_num = 0     #### change this to prevent overwriting gifs in same env_name folder\n",
    "\n",
    "# adjust following parameters to get desired duration, size (bytes) and smoothness of gif\n",
    "total_timesteps = 300\n",
    "step = 10\n",
    "frame_duration = 150\n",
    "\n",
    "\n",
    "# input images\n",
    "gif_images_dir = \"PPO_gif_images/\" + env_name + '/*.jpg'\n",
    "\n",
    "\n",
    "# ouput gif path\n",
    "gif_dir = \"PPO_gifs\"\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "\n",
    "gif_dir = gif_dir + '/' + env_name\n",
    "if not os.path.exists(gif_dir):\n",
    "    os.makedirs(gif_dir)\n",
    "\n",
    "gif_path = gif_dir + '/PPO_' + env_name + '_gif_' + str(gif_num) + '.gif'\n",
    "\n",
    "\n",
    "\n",
    "img_paths = sorted(glob.glob(gif_images_dir))\n",
    "img_paths = img_paths[:total_timesteps]\n",
    "img_paths = img_paths[::step]\n",
    "\n",
    "\n",
    "print(\"total frames in gif : \", len(img_paths))\n",
    "print(\"total duration of gif : \" + str(round(len(img_paths) * frame_duration / 1000, 2)) + \" seconds\")\n",
    "\n",
    "\n",
    "\n",
    "# save gif\n",
    "img, *imgs = [Image.open(f) for f in img_paths]\n",
    "img.save(fp=gif_path, format='GIF', append_images=imgs, save_all=True, optimize=True, duration=frame_duration, loop=0)\n",
    "\n",
    "print(\"saved gif at : \", gif_path)\n",
    "\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20d1bR8xHK5j"
   },
   "outputs": [],
   "source": [
    "\n",
    "############################# check gif byte size ##############################\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "# env_name = 'LunarLander-v2'\n",
    "# env_name = 'BipedalWalker-v2'\n",
    "# env_name = 'RoboschoolWalker2d-v1'\n",
    "\n",
    "\n",
    "gif_dir = \"PPO_gifs/\" + env_name + '/*.gif'\n",
    "\n",
    "gif_paths = sorted(glob.glob(gif_dir))\n",
    "\n",
    "for gif_path in gif_paths:\n",
    "    file_size = os.path.getsize(gif_path)\n",
    "    print(gif_path + '\\t\\t' + str(round(file_size / (1024 * 1024), 2)) + \" MB\")\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rM5UIAkcGxeA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "################################# End of Part V ################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YUzQOu1HYHR"
   },
   "source": [
    "################################################################################\n",
    "\n",
    "---------------------------------------------------------------------------- That's all folks ! ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "################################################################################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "e7JowRQEGGKQ",
    "Z4VJcUT2GlJz"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
